{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import time\n",
    "import re\n",
    "import hashlib\n",
    "import networkx as nx\n",
    "import sqlite3\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tokens\n",
    "config = configparser.ConfigParser()\n",
    "config.read('configfile.ini')\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "# authenticate\n",
    "auth = tweepy.OAuth2AppHandler(api_key, api_key_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_dataframe(working_df, tweets, hashtag):\n",
    "    #working_df=working_df.drop_duplicates()\n",
    "    print(f'working on {hashtag}')\n",
    "    index=len(working_df)\n",
    "    for tweet in tweets: \n",
    "        working_df.loc[index,'tweet_id']=tweet.id\n",
    "        working_df.loc[index,'created_at']=tweet.created_at\n",
    "        working_df.loc[index,'user']=tweet.user.screen_name\n",
    "        working_df.loc[index,'full_text']=tweet.full_text\n",
    "        working_df.loc[index,'favorite_count']=tweet.favorite_count\n",
    "        working_df.loc[index,'retweet_count']=tweet.retweet_count\n",
    "        working_df.loc[index,'hashtags']=hashtag\n",
    "        #print(working_df.loc[index,'created_at'])\n",
    "        #working_df=working_df.drop_duplicates()\n",
    "        index+=1\n",
    "        working_df.to_csv(f'source/{hashtag}.csv', index=False)\n",
    "        #time.sleep(1)\n",
    "    working_df=working_df.drop_duplicates()\n",
    "    working_df.to_csv(f'source/{hashtag}.csv', index=False)\n",
    "    working_df['created_at'] = pd.to_datetime(working_df['created_at'], utc=True)\n",
    "    # Group the DataFrame by day\n",
    "    grouped_df = working_df.groupby(pd.Grouper(key='created_at', freq='D'))\n",
    "\n",
    "    # Calculate the count of rows for each day\n",
    "    count_per_day = grouped_df['hashtags'].count()\n",
    "\n",
    "    # Display the count per day\n",
    "    print(count_per_day)\n",
    "          \n",
    "    return working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_from_general_tags(working_df, hashtag):\n",
    "    #load and merge the general_tags\n",
    "    print(f'working on {hashtag}')\n",
    "    general_tags = ['#SaveLockwoodandCo', 'Lockwood and Co']\n",
    "    general_tags_df=pd.DataFrame()\n",
    "    for tag in general_tags:\n",
    "        try:\n",
    "            general_tags_df=pd.concat([general_tags_df, pd.read_csv(f'source/{tag}.csv')], ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "    general_tags_df =general_tags_df.drop_duplicates()\n",
    "    print(f'total generaltags: {len(general_tags_df)}')\n",
    "    #general_tags_df['full_text'] = general_tags_df['full_text'].apply(lambda x: x.replace('\\n',' ').replace(':', ' '))\n",
    "    #Get the rows in the working_df that have the hashtag inside the full_text column\n",
    "    hashtag_df = general_tags_df[general_tags_df['full_text'].apply(lambda x: hashtag.lower() in x.lower())]\n",
    "    #hashtag_df = hashtag_df.reset_index(drop=True)\n",
    "    hashtag_df['hashtags'] = hashtag\n",
    "    working_df=pd.concat([working_df, hashtag_df], ignore_index=True)\n",
    "    working_df=working_df.drop_duplicates()\n",
    "    working_df['full_text'] = working_df['full_text'].apply(lambda x: x.replace('\\n',' ').replace(':', ' '))\n",
    "    working_df.to_csv(f'source/{hashtag}.csv', index=False)\n",
    "    working_df['created_at'] = pd.to_datetime(working_df['created_at'], utc=True)\n",
    "    # Group the DataFrame by day\n",
    "    grouped_df = working_df.groupby(pd.Grouper(key='created_at', freq='D'))\n",
    "\n",
    "    # Calculate the count of rows for each day\n",
    "    count_per_day = grouped_df['hashtags'].count()\n",
    "\n",
    "    # Display the count per day\n",
    "    print(count_per_day)\n",
    "  \n",
    "    return working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hash function to generate anonymized values\n",
    "def anonymize(value):\n",
    "    # Convert the value to a string and hash it using SHA256 algorithm\n",
    "    hashed_value = hashlib.sha256(str(value).encode()).hexdigest()\n",
    "    # Take the first 8 characters of the hash as the anonymized value\n",
    "    anonymized_value = hashed_value[:8]\n",
    "    return anonymized_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtagsweek1 = ['#FridayNightatPortlandRow', '#HauntedWatchParty', '#WatchPartyatPortlandRow', '#HauntedbyaType3','#TogetherForLockwoodandCo','#PrimeForLockwoodandCo','#BringBackLockwoodandCo']\n",
    "hashtagsweek2 = ['#GhostHuntersWatchParty', '#DisneyForLockwoodandCo', '#BBCforLockwoodandCo', '#AppleTVforLockwoodandCo', '#PrimeForLockwoodandCo', '#JustRecklessEnough']\n",
    "hashtagsweek3 = ['#LockwoodGhostAuditions', '#ParamountForLockwoodandCo', '#ScullandCo','#RapiersReady', '#CaringforCarlyle', '#DEPRACisOnTheWay', '#BunsForBunchurch']\n",
    "hashtagsweek4 = ['#CompleteFictionAppreciation', '#DisneySaveLockwood', '#ArtistryofLockwoodandCo', '#ParamountSaveLockwood', '#GhostStrike', '#LockwoodParallelFandoms', '#JustRecklessEnough']\n",
    "hashtagsweek5 = ['#StroudsAppreciation', '#VoteLockwoodforNFA', '#PrimeSaveLockwood', '#ScreamingStaircase', '#DEPRACrollcall', '#LivingforLockwood', '#RapiersReady']\n",
    "hashtagsweek6 = ['#LockNationAppreciation', '#LockNationArtistsandGiftsDay', '#LockNationEditorsDay', '#LockNationFicWritersDay', '#LockNationComediansDay', '#GhostLockAwards']\n",
    "hashtagsall = hashtagsweek1+hashtagsweek2+hashtagsweek3+hashtagsweek4 + hashtagsweek5\n",
    "hashtagsall = list(set(hashtagsall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16243\n",
      "working on Lockwood and Co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 157\n",
      "/tmp/ipykernel_899/1434055682.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  working_df['created_at'] = pd.to_datetime(working_df['created_at'], utc=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_at\n",
      "2023-06-02 00:00:00+00:00      64\n",
      "2023-06-03 00:00:00+00:00     313\n",
      "2023-06-04 00:00:00+00:00     275\n",
      "2023-06-05 00:00:00+00:00     443\n",
      "2023-06-06 00:00:00+00:00     725\n",
      "2023-06-07 00:00:00+00:00     922\n",
      "2023-06-08 00:00:00+00:00    1159\n",
      "2023-06-09 00:00:00+00:00    1710\n",
      "2023-06-10 00:00:00+00:00    1937\n",
      "2023-06-11 00:00:00+00:00    2756\n",
      "2023-06-12 00:00:00+00:00     407\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00    4878\n",
      "2023-06-16 00:00:00+00:00    4023\n",
      "2023-06-17 00:00:00+00:00    2049\n",
      "2023-06-18 00:00:00+00:00    2315\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "22673\n",
      "23976\n",
      "working on Lockwood and Co\n",
      "created_at\n",
      "2023-06-02 00:00:00+00:00      64\n",
      "2023-06-03 00:00:00+00:00     313\n",
      "2023-06-04 00:00:00+00:00     275\n",
      "2023-06-05 00:00:00+00:00     443\n",
      "2023-06-06 00:00:00+00:00     725\n",
      "2023-06-07 00:00:00+00:00     922\n",
      "2023-06-08 00:00:00+00:00    1159\n",
      "2023-06-09 00:00:00+00:00    1710\n",
      "2023-06-10 00:00:00+00:00    1937\n",
      "2023-06-11 00:00:00+00:00    2756\n",
      "2023-06-12 00:00:00+00:00     407\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00    6621\n",
      "2023-06-16 00:00:00+00:00    7429\n",
      "2023-06-17 00:00:00+00:00    5424\n",
      "2023-06-18 00:00:00+00:00    6069\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "28020\n"
     ]
    }
   ],
   "source": [
    "\n",
    "phrase = 'Lockwood and Co'\n",
    "try:\n",
    "    working_df = pd.read_csv(f'source/{phrase}.csv')\n",
    "    print(len(working_df))\n",
    "except:\n",
    "    working_df = pd.DataFrame(columns=['tweet_id', 'created_at', 'user', 'full_text', 'favorite_count', 'retweet_count', 'hashtags'])\n",
    "    \n",
    "tweets = tweepy.Cursor(api.search_tweets, q=phrase, tweet_mode='extended').items()\n",
    "working_df = get_tweets_dataframe(working_df, tweets, phrase)\n",
    "    \n",
    "working_df.drop_duplicates(inplace=True)\n",
    "print(len(working_df))\n",
    "    \n",
    "time.sleep(60)\n",
    "\n",
    "hashtag = '#SaveLockwoodandCo'\n",
    "try:\n",
    "    working_df = pd.read_csv(f'source/{phrase}.csv')\n",
    "    print(len(working_df))\n",
    "except:\n",
    "    working_df = pd.DataFrame(columns=['tweet_id', 'created_at', 'user', 'full_text', 'favorite_count', 'retweet_count', 'hashtags'])\n",
    "    \n",
    "tweets = tweepy.Cursor(api.search_tweets, q=hashtag, tweet_mode='extended').items()\n",
    "working_df = get_tweets_dataframe(working_df, tweets, phrase)\n",
    "    \n",
    "working_df.drop_duplicates(inplace=True)\n",
    "print(len(working_df))\n",
    "    \n",
    "time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "working on #PrimeSaveLockwood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14853/3429170079.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  working_df['created_at'] = pd.to_datetime(working_df['created_at'], utc=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_at\n",
      "2023-06-09 00:00:00+00:00      1\n",
      "2023-06-10 00:00:00+00:00      0\n",
      "2023-06-11 00:00:00+00:00      0\n",
      "2023-06-12 00:00:00+00:00      0\n",
      "2023-06-13 00:00:00+00:00      0\n",
      "2023-06-14 00:00:00+00:00      0\n",
      "2023-06-15 00:00:00+00:00    688\n",
      "2023-06-16 00:00:00+00:00    117\n",
      "2023-06-17 00:00:00+00:00     14\n",
      "2023-06-18 00:00:00+00:00     10\n",
      "2023-06-19 00:00:00+00:00      4\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "826\n"
     ]
    }
   ],
   "source": [
    "hashtags = ['#PrimeSaveLockwood']\n",
    "for hashtag in hashtags:\n",
    "    try:\n",
    "        working_df=pd.read_csv(f'source/{hashtag}.csv')\n",
    "        #working_df = pd.read_csv('source/#SkullandCo.csv')\n",
    "        print(len(working_df))\n",
    "    except:\n",
    "        working_df=pd.DataFrame(columns=['tweet_id','created_at', 'user', 'full_text','favorite_count','retweet_count','hashtags'])\n",
    "    tweets = tweepy.Cursor(api.search_tweets, q=hashtag, tweet_mode='extended').items()\n",
    "    working_df = get_tweets_dataframe(working_df, tweets, hashtag)\n",
    "    working_df=working_df.drop_duplicates()\n",
    "    print(len(working_df))\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try\n",
      "working on #VoteLockwoodforNFA\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-12 00:00:00+00:00      33\n",
      "2023-06-13 00:00:00+00:00    3453\n",
      "2023-06-14 00:00:00+00:00     683\n",
      "2023-06-15 00:00:00+00:00     106\n",
      "2023-06-16 00:00:00+00:00      71\n",
      "2023-06-17 00:00:00+00:00       4\n",
      "2023-06-18 00:00:00+00:00       3\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #DisneyForLockwoodandCo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14853/2862647720.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hashtag_df['hashtags'] = hashtag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-22 00:00:00+00:00      35\n",
      "2023-05-23 00:00:00+00:00    4179\n",
      "2023-05-24 00:00:00+00:00    1275\n",
      "2023-05-25 00:00:00+00:00     231\n",
      "2023-05-26 00:00:00+00:00      45\n",
      "2023-05-27 00:00:00+00:00       6\n",
      "2023-05-28 00:00:00+00:00      17\n",
      "2023-05-29 00:00:00+00:00      15\n",
      "2023-05-30 00:00:00+00:00       3\n",
      "2023-05-31 00:00:00+00:00      11\n",
      "2023-06-01 00:00:00+00:00       4\n",
      "2023-06-02 00:00:00+00:00       6\n",
      "2023-06-03 00:00:00+00:00       0\n",
      "2023-06-04 00:00:00+00:00       0\n",
      "2023-06-05 00:00:00+00:00       3\n",
      "2023-06-06 00:00:00+00:00      12\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       0\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       2\n",
      "2023-06-11 00:00:00+00:00       5\n",
      "2023-06-12 00:00:00+00:00       0\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00       0\n",
      "2023-06-16 00:00:00+00:00       2\n",
      "2023-06-17 00:00:00+00:00       5\n",
      "2023-06-18 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #DisneySaveLockwood\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-05 00:00:00+00:00      10\n",
      "2023-06-06 00:00:00+00:00    3778\n",
      "2023-06-07 00:00:00+00:00    1104\n",
      "2023-06-08 00:00:00+00:00     110\n",
      "2023-06-09 00:00:00+00:00       5\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00       7\n",
      "2023-06-12 00:00:00+00:00       1\n",
      "2023-06-13 00:00:00+00:00       1\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00       2\n",
      "2023-06-16 00:00:00+00:00       1\n",
      "2023-06-17 00:00:00+00:00       0\n",
      "2023-06-18 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #DEPRACisOnTheWay\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-02 00:00:00+00:00      42\n",
      "2023-06-03 00:00:00+00:00    4390\n",
      "2023-06-04 00:00:00+00:00     910\n",
      "2023-06-05 00:00:00+00:00      56\n",
      "2023-06-06 00:00:00+00:00       7\n",
      "2023-06-07 00:00:00+00:00       1\n",
      "2023-06-08 00:00:00+00:00       0\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00       4\n",
      "2023-06-12 00:00:00+00:00       0\n",
      "2023-06-13 00:00:00+00:00       1\n",
      "2023-06-14 00:00:00+00:00       2\n",
      "2023-06-15 00:00:00+00:00       0\n",
      "2023-06-16 00:00:00+00:00       4\n",
      "2023-06-17 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #LockwoodParallelFandoms\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-07 00:00:00+00:00       1\n",
      "2023-06-08 00:00:00+00:00       0\n",
      "2023-06-09 00:00:00+00:00      23\n",
      "2023-06-10 00:00:00+00:00    5929\n",
      "2023-06-11 00:00:00+00:00    1713\n",
      "2023-06-12 00:00:00+00:00      75\n",
      "2023-06-13 00:00:00+00:00       4\n",
      "2023-06-14 00:00:00+00:00       1\n",
      "2023-06-15 00:00:00+00:00      10\n",
      "2023-06-16 00:00:00+00:00       0\n",
      "2023-06-17 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #CaringforCarlyle\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-28 00:00:00+00:00       1\n",
      "2023-05-29 00:00:00+00:00       1\n",
      "2023-05-30 00:00:00+00:00       0\n",
      "2023-05-31 00:00:00+00:00       0\n",
      "2023-06-01 00:00:00+00:00      16\n",
      "2023-06-02 00:00:00+00:00    4660\n",
      "2023-06-03 00:00:00+00:00    1514\n",
      "2023-06-04 00:00:00+00:00      65\n",
      "2023-06-05 00:00:00+00:00       4\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       2\n",
      "2023-06-08 00:00:00+00:00      11\n",
      "2023-06-09 00:00:00+00:00       1\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00       5\n",
      "2023-06-12 00:00:00+00:00       1\n",
      "2023-06-13 00:00:00+00:00       3\n",
      "2023-06-14 00:00:00+00:00       4\n",
      "2023-06-15 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #WatchPartyatPortlandRow\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-20 00:00:00+00:00       1\n",
      "2023-05-21 00:00:00+00:00    3902\n",
      "2023-05-22 00:00:00+00:00    1243\n",
      "2023-05-23 00:00:00+00:00      92\n",
      "2023-05-24 00:00:00+00:00       8\n",
      "2023-05-25 00:00:00+00:00       1\n",
      "2023-05-26 00:00:00+00:00       0\n",
      "2023-05-27 00:00:00+00:00       0\n",
      "2023-05-28 00:00:00+00:00       2\n",
      "2023-05-29 00:00:00+00:00       0\n",
      "2023-05-30 00:00:00+00:00       3\n",
      "2023-05-31 00:00:00+00:00       0\n",
      "2023-06-01 00:00:00+00:00       2\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00       0\n",
      "2023-06-04 00:00:00+00:00       0\n",
      "2023-06-05 00:00:00+00:00       0\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #BringBackLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-15 00:00:00+00:00    3522\n",
      "2023-05-16 00:00:00+00:00    2649\n",
      "2023-05-17 00:00:00+00:00     854\n",
      "2023-05-18 00:00:00+00:00     346\n",
      "2023-05-19 00:00:00+00:00      92\n",
      "2023-05-20 00:00:00+00:00      31\n",
      "2023-05-21 00:00:00+00:00      45\n",
      "2023-05-22 00:00:00+00:00      23\n",
      "2023-05-23 00:00:00+00:00      22\n",
      "2023-05-24 00:00:00+00:00      21\n",
      "2023-05-25 00:00:00+00:00      13\n",
      "2023-05-26 00:00:00+00:00      17\n",
      "2023-05-27 00:00:00+00:00      14\n",
      "2023-05-28 00:00:00+00:00      19\n",
      "2023-05-29 00:00:00+00:00      21\n",
      "2023-05-30 00:00:00+00:00      28\n",
      "2023-05-31 00:00:00+00:00      21\n",
      "2023-06-01 00:00:00+00:00      28\n",
      "2023-06-02 00:00:00+00:00      11\n",
      "2023-06-03 00:00:00+00:00      12\n",
      "2023-06-04 00:00:00+00:00       7\n",
      "2023-06-05 00:00:00+00:00       1\n",
      "2023-06-06 00:00:00+00:00       1\n",
      "2023-06-07 00:00:00+00:00       4\n",
      "2023-06-08 00:00:00+00:00      14\n",
      "2023-06-09 00:00:00+00:00       6\n",
      "2023-06-10 00:00:00+00:00       2\n",
      "2023-06-11 00:00:00+00:00       4\n",
      "2023-06-12 00:00:00+00:00       2\n",
      "2023-06-13 00:00:00+00:00       5\n",
      "2023-06-14 00:00:00+00:00       4\n",
      "2023-06-15 00:00:00+00:00       2\n",
      "2023-06-16 00:00:00+00:00       8\n",
      "2023-06-17 00:00:00+00:00       2\n",
      "2023-06-18 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #GhostStrike\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-08 00:00:00+00:00      11\n",
      "2023-06-09 00:00:00+00:00    4749\n",
      "2023-06-10 00:00:00+00:00    1455\n",
      "2023-06-11 00:00:00+00:00      93\n",
      "2023-06-12 00:00:00+00:00      26\n",
      "2023-06-13 00:00:00+00:00       1\n",
      "2023-06-14 00:00:00+00:00       3\n",
      "2023-06-15 00:00:00+00:00       6\n",
      "2023-06-16 00:00:00+00:00       1\n",
      "2023-06-17 00:00:00+00:00       4\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #TogetherForLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-16 00:00:00+00:00       3\n",
      "2023-05-17 00:00:00+00:00    6466\n",
      "2023-05-18 00:00:00+00:00    2568\n",
      "2023-05-19 00:00:00+00:00     242\n",
      "2023-05-20 00:00:00+00:00      23\n",
      "2023-05-21 00:00:00+00:00       7\n",
      "2023-05-22 00:00:00+00:00      15\n",
      "2023-05-23 00:00:00+00:00      10\n",
      "2023-05-24 00:00:00+00:00       8\n",
      "2023-05-25 00:00:00+00:00       8\n",
      "2023-05-26 00:00:00+00:00       4\n",
      "2023-05-27 00:00:00+00:00       4\n",
      "2023-05-28 00:00:00+00:00       4\n",
      "2023-05-29 00:00:00+00:00       0\n",
      "2023-05-30 00:00:00+00:00      10\n",
      "2023-05-31 00:00:00+00:00      11\n",
      "2023-06-01 00:00:00+00:00       5\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00       2\n",
      "2023-06-04 00:00:00+00:00       3\n",
      "2023-06-05 00:00:00+00:00       0\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       7\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00      13\n",
      "2023-06-12 00:00:00+00:00       0\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00       0\n",
      "2023-06-16 00:00:00+00:00       0\n",
      "2023-06-17 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #HauntedWatchParty\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-20 00:00:00+00:00    3433\n",
      "2023-05-21 00:00:00+00:00    1237\n",
      "2023-05-22 00:00:00+00:00     112\n",
      "2023-05-23 00:00:00+00:00      38\n",
      "2023-05-24 00:00:00+00:00       0\n",
      "2023-05-25 00:00:00+00:00       3\n",
      "2023-05-26 00:00:00+00:00       0\n",
      "2023-05-27 00:00:00+00:00      10\n",
      "2023-05-28 00:00:00+00:00       0\n",
      "2023-05-29 00:00:00+00:00       0\n",
      "2023-05-30 00:00:00+00:00       0\n",
      "2023-05-31 00:00:00+00:00       1\n",
      "2023-06-01 00:00:00+00:00       0\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00       2\n",
      "2023-06-04 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #LivingforLockwood\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-16 00:00:00+00:00      38\n",
      "2023-06-17 00:00:00+00:00    5122\n",
      "2023-06-18 00:00:00+00:00    1059\n",
      "2023-06-19 00:00:00+00:00      23\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #PrimeForLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-14 00:00:00+00:00       1\n",
      "2023-05-15 00:00:00+00:00       3\n",
      "2023-05-16 00:00:00+00:00    5463\n",
      "2023-05-17 00:00:00+00:00    3167\n",
      "2023-05-18 00:00:00+00:00     331\n",
      "2023-05-19 00:00:00+00:00      76\n",
      "2023-05-20 00:00:00+00:00      36\n",
      "2023-05-21 00:00:00+00:00       3\n",
      "2023-05-22 00:00:00+00:00      32\n",
      "2023-05-23 00:00:00+00:00      14\n",
      "2023-05-24 00:00:00+00:00       4\n",
      "2023-05-25 00:00:00+00:00      43\n",
      "2023-05-26 00:00:00+00:00    4166\n",
      "2023-05-27 00:00:00+00:00    1609\n",
      "2023-05-28 00:00:00+00:00     122\n",
      "2023-05-29 00:00:00+00:00      33\n",
      "2023-05-30 00:00:00+00:00      25\n",
      "2023-05-31 00:00:00+00:00      27\n",
      "2023-06-01 00:00:00+00:00       5\n",
      "2023-06-02 00:00:00+00:00      15\n",
      "2023-06-03 00:00:00+00:00       8\n",
      "2023-06-04 00:00:00+00:00      14\n",
      "2023-06-05 00:00:00+00:00       1\n",
      "2023-06-06 00:00:00+00:00       4\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       9\n",
      "2023-06-09 00:00:00+00:00       7\n",
      "2023-06-10 00:00:00+00:00       2\n",
      "2023-06-11 00:00:00+00:00       0\n",
      "2023-06-12 00:00:00+00:00       0\n",
      "2023-06-13 00:00:00+00:00       1\n",
      "2023-06-14 00:00:00+00:00      12\n",
      "2023-06-15 00:00:00+00:00      10\n",
      "2023-06-16 00:00:00+00:00       0\n",
      "2023-06-17 00:00:00+00:00       0\n",
      "2023-06-18 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #ArtistryofLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-06 00:00:00+00:00      2\n",
      "2023-06-07 00:00:00+00:00    933\n",
      "2023-06-08 00:00:00+00:00    995\n",
      "2023-06-09 00:00:00+00:00     62\n",
      "2023-06-10 00:00:00+00:00     10\n",
      "2023-06-11 00:00:00+00:00     29\n",
      "2023-06-12 00:00:00+00:00      7\n",
      "2023-06-13 00:00:00+00:00      3\n",
      "2023-06-14 00:00:00+00:00      1\n",
      "2023-06-15 00:00:00+00:00      2\n",
      "2023-06-16 00:00:00+00:00      1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #ScreamingStaircase\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-14 00:00:00+00:00       9\n",
      "2023-06-15 00:00:00+00:00    5850\n",
      "2023-06-16 00:00:00+00:00    1305\n",
      "2023-06-17 00:00:00+00:00       9\n",
      "2023-06-18 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #BBCforLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-22 00:00:00+00:00      27\n",
      "2023-05-23 00:00:00+00:00       1\n",
      "2023-05-24 00:00:00+00:00    3881\n",
      "2023-05-25 00:00:00+00:00    1297\n",
      "2023-05-26 00:00:00+00:00     108\n",
      "2023-05-27 00:00:00+00:00      13\n",
      "2023-05-28 00:00:00+00:00      13\n",
      "2023-05-29 00:00:00+00:00      11\n",
      "2023-05-30 00:00:00+00:00       5\n",
      "2023-05-31 00:00:00+00:00       8\n",
      "2023-06-01 00:00:00+00:00       0\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00       3\n",
      "2023-06-04 00:00:00+00:00       2\n",
      "2023-06-05 00:00:00+00:00       3\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       3\n",
      "2023-06-09 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #AppleTVforLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-22 00:00:00+00:00      27\n",
      "2023-05-23 00:00:00+00:00       1\n",
      "2023-05-24 00:00:00+00:00       3\n",
      "2023-05-25 00:00:00+00:00    3676\n",
      "2023-05-26 00:00:00+00:00     927\n",
      "2023-05-27 00:00:00+00:00      64\n",
      "2023-05-28 00:00:00+00:00      14\n",
      "2023-05-29 00:00:00+00:00       3\n",
      "2023-05-30 00:00:00+00:00       2\n",
      "2023-05-31 00:00:00+00:00       2\n",
      "2023-06-01 00:00:00+00:00      19\n",
      "2023-06-02 00:00:00+00:00       3\n",
      "2023-06-03 00:00:00+00:00       1\n",
      "2023-06-04 00:00:00+00:00       2\n",
      "2023-06-05 00:00:00+00:00       0\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       0\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00       0\n",
      "2023-06-12 00:00:00+00:00       0\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #HauntedbyaType3\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-16 00:00:00+00:00       1\n",
      "2023-05-17 00:00:00+00:00       0\n",
      "2023-05-18 00:00:00+00:00    4062\n",
      "2023-05-19 00:00:00+00:00    1555\n",
      "2023-05-20 00:00:00+00:00     143\n",
      "2023-05-21 00:00:00+00:00      33\n",
      "2023-05-22 00:00:00+00:00       4\n",
      "2023-05-23 00:00:00+00:00       6\n",
      "2023-05-24 00:00:00+00:00       1\n",
      "2023-05-25 00:00:00+00:00       1\n",
      "2023-05-26 00:00:00+00:00       0\n",
      "2023-05-27 00:00:00+00:00       0\n",
      "2023-05-28 00:00:00+00:00       0\n",
      "2023-05-29 00:00:00+00:00       0\n",
      "2023-05-30 00:00:00+00:00       2\n",
      "2023-05-31 00:00:00+00:00       1\n",
      "2023-06-01 00:00:00+00:00       1\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00       0\n",
      "2023-06-04 00:00:00+00:00       0\n",
      "2023-06-05 00:00:00+00:00       0\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       0\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00       0\n",
      "2023-06-12 00:00:00+00:00       0\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00       0\n",
      "2023-06-16 00:00:00+00:00       0\n",
      "2023-06-17 00:00:00+00:00       0\n",
      "2023-06-18 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #JustRecklessEnough\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-22 00:00:00+00:00      27\n",
      "2023-05-23 00:00:00+00:00       0\n",
      "2023-05-24 00:00:00+00:00       0\n",
      "2023-05-25 00:00:00+00:00       0\n",
      "2023-05-26 00:00:00+00:00      26\n",
      "2023-05-27 00:00:00+00:00    3242\n",
      "2023-05-28 00:00:00+00:00    4930\n",
      "2023-05-29 00:00:00+00:00    1575\n",
      "2023-05-30 00:00:00+00:00     149\n",
      "2023-05-31 00:00:00+00:00      19\n",
      "2023-06-01 00:00:00+00:00      22\n",
      "2023-06-02 00:00:00+00:00      14\n",
      "2023-06-03 00:00:00+00:00      14\n",
      "2023-06-04 00:00:00+00:00       4\n",
      "2023-06-05 00:00:00+00:00      13\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       0\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00      33\n",
      "2023-06-11 00:00:00+00:00    6371\n",
      "2023-06-12 00:00:00+00:00    2335\n",
      "2023-06-13 00:00:00+00:00      77\n",
      "2023-06-14 00:00:00+00:00       9\n",
      "2023-06-15 00:00:00+00:00       5\n",
      "2023-06-16 00:00:00+00:00       2\n",
      "2023-06-17 00:00:00+00:00       6\n",
      "2023-06-18 00:00:00+00:00       1\n",
      "2023-06-19 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #ParamountSaveLockwood\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-07 00:00:00+00:00       8\n",
      "2023-06-08 00:00:00+00:00    7329\n",
      "2023-06-09 00:00:00+00:00    1781\n",
      "2023-06-10 00:00:00+00:00      37\n",
      "2023-06-11 00:00:00+00:00      26\n",
      "2023-06-12 00:00:00+00:00       1\n",
      "2023-06-13 00:00:00+00:00       1\n",
      "2023-06-14 00:00:00+00:00       8\n",
      "2023-06-15 00:00:00+00:00       4\n",
      "2023-06-16 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #DEPRACrollcall\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-15 00:00:00+00:00      24\n",
      "2023-06-16 00:00:00+00:00    4503\n",
      "2023-06-17 00:00:00+00:00     504\n",
      "2023-06-18 00:00:00+00:00      37\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #CompleteFictionAppreciation\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-04 00:00:00+00:00       9\n",
      "2023-06-05 00:00:00+00:00    6708\n",
      "2023-06-06 00:00:00+00:00    1983\n",
      "2023-06-07 00:00:00+00:00      32\n",
      "2023-06-08 00:00:00+00:00       2\n",
      "2023-06-09 00:00:00+00:00       1\n",
      "2023-06-10 00:00:00+00:00       1\n",
      "2023-06-11 00:00:00+00:00       8\n",
      "2023-06-12 00:00:00+00:00      14\n",
      "2023-06-13 00:00:00+00:00      23\n",
      "2023-06-14 00:00:00+00:00       1\n",
      "2023-06-15 00:00:00+00:00      24\n",
      "2023-06-16 00:00:00+00:00      10\n",
      "2023-06-17 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #PrimeSaveLockwood\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-09 00:00:00+00:00      2\n",
      "2023-06-10 00:00:00+00:00      0\n",
      "2023-06-11 00:00:00+00:00      0\n",
      "2023-06-12 00:00:00+00:00      0\n",
      "2023-06-13 00:00:00+00:00      0\n",
      "2023-06-14 00:00:00+00:00      0\n",
      "2023-06-15 00:00:00+00:00    787\n",
      "2023-06-16 00:00:00+00:00    128\n",
      "2023-06-17 00:00:00+00:00     16\n",
      "2023-06-18 00:00:00+00:00     12\n",
      "2023-06-19 00:00:00+00:00      4\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #ParamountForLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-28 00:00:00+00:00       1\n",
      "2023-05-29 00:00:00+00:00      38\n",
      "2023-05-30 00:00:00+00:00    7066\n",
      "2023-05-31 00:00:00+00:00    2501\n",
      "2023-06-01 00:00:00+00:00     144\n",
      "2023-06-02 00:00:00+00:00      15\n",
      "2023-06-03 00:00:00+00:00       8\n",
      "2023-06-04 00:00:00+00:00      12\n",
      "2023-06-05 00:00:00+00:00      12\n",
      "2023-06-06 00:00:00+00:00       4\n",
      "2023-06-07 00:00:00+00:00       6\n",
      "2023-06-08 00:00:00+00:00     110\n",
      "2023-06-09 00:00:00+00:00      12\n",
      "2023-06-10 00:00:00+00:00       4\n",
      "2023-06-11 00:00:00+00:00       2\n",
      "2023-06-12 00:00:00+00:00       0\n",
      "2023-06-13 00:00:00+00:00       2\n",
      "2023-06-14 00:00:00+00:00       4\n",
      "2023-06-15 00:00:00+00:00       3\n",
      "2023-06-16 00:00:00+00:00       2\n",
      "2023-06-17 00:00:00+00:00       4\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #BunsForBunchurch\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-29 00:00:00+00:00       7\n",
      "2023-05-30 00:00:00+00:00       2\n",
      "2023-05-31 00:00:00+00:00       2\n",
      "2023-06-01 00:00:00+00:00       1\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00      10\n",
      "2023-06-04 00:00:00+00:00    7890\n",
      "2023-06-05 00:00:00+00:00    1225\n",
      "2023-06-06 00:00:00+00:00      34\n",
      "2023-06-07 00:00:00+00:00      18\n",
      "2023-06-08 00:00:00+00:00      29\n",
      "2023-06-09 00:00:00+00:00      17\n",
      "2023-06-10 00:00:00+00:00      17\n",
      "2023-06-11 00:00:00+00:00      20\n",
      "2023-06-12 00:00:00+00:00       2\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       1\n",
      "2023-06-15 00:00:00+00:00       0\n",
      "2023-06-16 00:00:00+00:00       4\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #RapiersReady\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-28 00:00:00+00:00       1\n",
      "2023-05-29 00:00:00+00:00       0\n",
      "2023-05-30 00:00:00+00:00       0\n",
      "2023-05-31 00:00:00+00:00      39\n",
      "2023-06-01 00:00:00+00:00    5780\n",
      "2023-06-02 00:00:00+00:00    1421\n",
      "2023-06-03 00:00:00+00:00      36\n",
      "2023-06-04 00:00:00+00:00       3\n",
      "2023-06-05 00:00:00+00:00       1\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       2\n",
      "2023-06-08 00:00:00+00:00       9\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00       3\n",
      "2023-06-12 00:00:00+00:00      10\n",
      "2023-06-13 00:00:00+00:00       1\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00       0\n",
      "2023-06-16 00:00:00+00:00       1\n",
      "2023-06-17 00:00:00+00:00      26\n",
      "2023-06-18 00:00:00+00:00    6207\n",
      "2023-06-19 00:00:00+00:00     545\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #ScullandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-31 00:00:00+00:00    1\n",
      "2023-06-01 00:00:00+00:00    2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #GhostHuntersWatchParty\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-21 00:00:00+00:00      11\n",
      "2023-05-22 00:00:00+00:00    3430\n",
      "2023-05-23 00:00:00+00:00     695\n",
      "2023-05-24 00:00:00+00:00      48\n",
      "2023-05-25 00:00:00+00:00      38\n",
      "2023-05-26 00:00:00+00:00       2\n",
      "2023-05-27 00:00:00+00:00       2\n",
      "2023-05-28 00:00:00+00:00       0\n",
      "2023-05-29 00:00:00+00:00       8\n",
      "2023-05-30 00:00:00+00:00       2\n",
      "2023-05-31 00:00:00+00:00       1\n",
      "2023-06-01 00:00:00+00:00       4\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00       0\n",
      "2023-06-04 00:00:00+00:00       1\n",
      "2023-06-05 00:00:00+00:00       2\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       1\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       2\n",
      "2023-06-11 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #LockwoodGhostAuditions\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-28 00:00:00+00:00      40\n",
      "2023-05-29 00:00:00+00:00    5292\n",
      "2023-05-30 00:00:00+00:00    1072\n",
      "2023-05-31 00:00:00+00:00      41\n",
      "2023-06-01 00:00:00+00:00      11\n",
      "2023-06-02 00:00:00+00:00       2\n",
      "2023-06-03 00:00:00+00:00       2\n",
      "2023-06-04 00:00:00+00:00       2\n",
      "2023-06-05 00:00:00+00:00       0\n",
      "2023-06-06 00:00:00+00:00       1\n",
      "2023-06-07 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #StroudsAppreciation\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-11 00:00:00+00:00      16\n",
      "2023-06-12 00:00:00+00:00    2877\n",
      "2023-06-13 00:00:00+00:00     530\n",
      "2023-06-14 00:00:00+00:00      34\n",
      "2023-06-15 00:00:00+00:00      16\n",
      "2023-06-16 00:00:00+00:00       6\n",
      "2023-06-17 00:00:00+00:00       2\n",
      "2023-06-18 00:00:00+00:00       4\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #FridayNightatPortlandRow\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-18 00:00:00+00:00       3\n",
      "2023-05-19 00:00:00+00:00    3518\n",
      "2023-05-20 00:00:00+00:00    1363\n",
      "2023-05-21 00:00:00+00:00     196\n",
      "2023-05-22 00:00:00+00:00      53\n",
      "2023-05-23 00:00:00+00:00      17\n",
      "2023-05-24 00:00:00+00:00       8\n",
      "2023-05-25 00:00:00+00:00       1\n",
      "2023-05-26 00:00:00+00:00       0\n",
      "2023-05-27 00:00:00+00:00       6\n",
      "2023-05-28 00:00:00+00:00      15\n",
      "2023-05-29 00:00:00+00:00       3\n",
      "2023-05-30 00:00:00+00:00       0\n",
      "2023-05-31 00:00:00+00:00       1\n",
      "2023-06-01 00:00:00+00:00       4\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00       3\n",
      "2023-06-04 00:00:00+00:00       9\n",
      "2023-06-05 00:00:00+00:00       0\n",
      "2023-06-06 00:00:00+00:00       2\n",
      "2023-06-07 00:00:00+00:00       3\n",
      "2023-06-08 00:00:00+00:00       0\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00       1\n",
      "2023-06-12 00:00:00+00:00       2\n",
      "2023-06-13 00:00:00+00:00       1\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00       4\n",
      "Freq: D, Name: hashtags, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "hashtags = ['#SkullandCo']\n",
    "for hashtag in hashtagsall:\n",
    "    try:\n",
    "        \n",
    "        working_df=pd.read_csv(f'source/{hashtag}.csv')\n",
    "        print('try')\n",
    "        working_df = get_tweets_from_general_tags(working_df, hashtag)\n",
    "    except:\n",
    "        working_df=pd.DataFrame(columns=['tweet_id','created_at', 'user', 'full_text','favorite_count','retweet_count','hashtags'])\n",
    "        print('except')\n",
    "        working_df = get_tweets_from_general_tags(working_df, hashtag)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210681"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df=pd.DataFrame()\n",
    "for hashtag in hashtagsall:\n",
    "    try:\n",
    "        working_df=pd.concat([working_df, pd.read_csv(f'source/{hashtag}.csv')], ignore_index=True)\n",
    "    except:\n",
    "        pass\n",
    "len(working_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df['full_text'] = working_df['full_text'].str.replace(r'\"', '').replace(r'\\n', ' ').replace(':', ' ').replace(',', '').replace('!', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    116660\n",
       "True      94021\n",
       "Name: retweet, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column 'retweet' with default value False\n",
    "working_df['retweet'] = False\n",
    "\n",
    "# Check if 'full_text' starts with 'RT ' and set 'retweet' column accordingly\n",
    "working_df.loc[working_df['full_text'].str.startswith('RT '), 'retweet'] = True\n",
    "\n",
    "#Remove the 'RT ' in the full_text column\n",
    "working_df['full_text'] = working_df['full_text'].str.replace('RT ', '')\n",
    "\n",
    "working_df['retweet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_week_label(week_number):\n",
    "    if week_number == 20:\n",
    "        return 'week1'\n",
    "    elif week_number == 21:\n",
    "        return 'week2'\n",
    "    elif week_number == 22:\n",
    "        return 'week3'\n",
    "    elif week_number == 23:\n",
    "        return 'week4'\n",
    "    elif week_number == 24:\n",
    "        return 'week5'\n",
    "    elif week_number == 25:\n",
    "        return 'week6'\n",
    "    else:\n",
    "        return 'week1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "week4    47107\n",
       "week1    45386\n",
       "week3    45240\n",
       "week5    36259\n",
       "week2    36116\n",
       "week6      573\n",
       "Name: week, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df['created_date'] = pd.to_datetime(working_df['created_at'], utc=True)\n",
    "working_df['week'] = working_df['created_date'].dt.isocalendar().week\n",
    "working_df['week'] = working_df['week'].apply(get_week_label)\n",
    "working_df['week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an anonymized tweet_id\n",
    "#working_df['unique_id'] = str(working_df['tweet_id']) + working_df['created_at'] + working_df['user'] + str(working_df['retweet'])\n",
    "working_df['unique_id'] = working_df.apply(lambda row: str(row['tweet_id']) + row['created_at'] + row['user'] + str(row['retweet']), axis=1)\n",
    "working_df['tweet_id'] = working_df['unique_id'].apply(anonymize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hashtags\n",
       "#JustRecklessEnough             18875\n",
       "#PrimeForLockwoodandCo          15244\n",
       "#RapiersReady                   14085\n",
       "#ParamountForLockwoodandCo       9950\n",
       "#TogetherForLockwoodandCo        9415\n",
       "#BunsForBunchurch                9279\n",
       "#ParamountSaveLockwood           9196\n",
       "#CompleteFictionAppreciation     8818\n",
       "#BringBackLockwoodandCo          7853\n",
       "#LockwoodParallelFandoms         7758\n",
       "#ScreamingStaircase              7174\n",
       "#LockwoodGhostAuditions          6464\n",
       "#GhostStrike                     6349\n",
       "#CaringforCarlyle                6289\n",
       "#LivingforLockwood               6242\n",
       "#DisneyForLockwoodandCo          5858\n",
       "#HauntedbyaType3                 5811\n",
       "#DEPRACisOnTheWay                5419\n",
       "#BBCforLockwoodandCo             5377\n",
       "#WatchPartyatPortlandRow         5255\n",
       "#FridayNightatPortlandRow        5213\n",
       "#DEPRACrollcall                  5068\n",
       "#DisneySaveLockwood              5021\n",
       "#HauntedWatchParty               4838\n",
       "#AppleTVforLockwoodandCo         4746\n",
       "#VoteLockwoodforNFA              4353\n",
       "#GhostHuntersWatchParty          4249\n",
       "#StroudsAppreciation             3485\n",
       "#ArtistryofLockwoodandCo         2045\n",
       "#PrimeSaveLockwood                949\n",
       "#ScullandCo                         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags_df = working_df[['tweet_id','hashtags']]\n",
    "hashtags_df.to_csv('output/hashtags.csv', index=False)\n",
    "working_df.value_counts('hashtags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14853/3506489542.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  working_df['full_text'] = working_df['full_text'].str.replace(r'@(\\w+)', '')\n"
     ]
    }
   ],
   "source": [
    "# Get the tagged users from the full_text\n",
    "working_df=working_df.drop_duplicates('tweet_id')\n",
    "working_df['tagged_users'] = working_df['full_text'].apply(lambda x: re.findall(r'@(\\w+)', x))\n",
    "# Remove the tagged users from the full_text\n",
    "working_df['full_text'] = working_df['full_text'].str.replace(r'@(\\w+)', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a table for network analysis\n",
    "na_df = working_df[['tweet_id','user', 'retweet', 'tagged_users']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that would create a dataframe that shows the interaction\n",
    "def get_interaction(df):\n",
    "    func_df = pd.DataFrame(columns = ['tweet_id', 'from', 'to'])\n",
    "    for x in range(len(df)):\n",
    "        if df['retweet'][0]=='True':\n",
    "            new_row = {'tweet_id':df['tweet_id'].iloc[x], 'from':df['tagged_users'].iloc[x][0], 'to': df['user'].iloc[x]}\n",
    "            func_df = func_df.append(new_row, ignore_index = True)\n",
    "        else:\n",
    "            for user in df['tagged_users'].iloc[x]:\n",
    "                new_row = {'tweet_id':df['tweet_id'].iloc[x], 'to':user, 'from': df['user'].iloc[x]}\n",
    "                func_df = func_df.append(new_row, ignore_index = True)\n",
    "    return func_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_interac_df = get_interaction(na_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a unique user dataframe\n",
    "list_of_user = na_interac_df['from'].append(na_interac_df['to'], ignore_index=True)\n",
    "list_of_user = list(set(list_of_user))\n",
    "user_df = pd.DataFrame(list_of_user, columns=['username'])\n",
    "user_df['user'] = user_df['username'].apply(anonymize)\n",
    "user_df=user_df.sort_values('username').reset_index()\n",
    "user_df.to_csv('output/username.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anonymise the users from the different dataframes\n",
    "na_interac_df['from'] = na_interac_df['from'].map(user_df.set_index('username')['user'])\n",
    "na_interac_df['to'] = na_interac_df['to'].map(user_df.set_index('username')['user'])\n",
    "working_df['user'] = working_df['user'].map(user_df.set_index('username')['user'])\n",
    "na_interac_df.to_csv('output/userinteraction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user</th>\n",
       "      <th>full_text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweet</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9717a31e</td>\n",
       "      <td>2023-06-15 21:17:36+00:00</td>\n",
       "      <td>b5058ddc</td>\n",
       "      <td>This is our chance to show our love for Lock...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>True</td>\n",
       "      <td>week5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c2d93608</td>\n",
       "      <td>2023-06-15 21:04:07+00:00</td>\n",
       "      <td>4b288607</td>\n",
       "      <td>Feeling very hopeful that with our worldwide c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>week5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82369a19</td>\n",
       "      <td>2023-06-15 20:53:01+00:00</td>\n",
       "      <td>f328aa3d</td>\n",
       "      <td>This is our chance to show our love for Lock...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>True</td>\n",
       "      <td>week5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e50bab11</td>\n",
       "      <td>2023-06-15 20:51:58+00:00</td>\n",
       "      <td>ea3b9f01</td>\n",
       "      <td>‼️Hey, LockNation! Here's the great idea!🔥 W...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>week5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c00f39ee</td>\n",
       "      <td>2023-06-15 18:40:27+00:00</td>\n",
       "      <td>7d4d44e6</td>\n",
       "      <td>Your daily reminder to vote and share! #VoteLo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>week5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217648</th>\n",
       "      <td>def67d31</td>\n",
       "      <td>2023-06-18 09:54:34+00:00</td>\n",
       "      <td>e1888bba</td>\n",
       "      <td>If anything will make me resubscribe to ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>week5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217649</th>\n",
       "      <td>02a206ef</td>\n",
       "      <td>2023-06-16 14:09:26+00:00</td>\n",
       "      <td>a838dedb</td>\n",
       "      <td>Yes, Alice! Lockwood and Co taking all the wi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>week5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217650</th>\n",
       "      <td>f17410cd</td>\n",
       "      <td>2023-06-15 12:15:25+00:00</td>\n",
       "      <td>62f322a1</td>\n",
       "      <td>#SaveLockwoodandCo  #LockwoodandCo #DisneySa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>True</td>\n",
       "      <td>week5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217651</th>\n",
       "      <td>254011dc</td>\n",
       "      <td>2023-06-13 18:01:23+00:00</td>\n",
       "      <td>a7ebdbee</td>\n",
       "      <td>I FINALLY FINISHED IT, OH GHAD, BUT I PRESEN...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>True</td>\n",
       "      <td>week5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217652</th>\n",
       "      <td>470d58f7</td>\n",
       "      <td>2023-06-12 20:59:16+00:00</td>\n",
       "      <td>cafb9d63</td>\n",
       "      <td>Can anyone see our hashtags trending right n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>week5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143458 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_id                 created_at      user  \\\n",
       "0       9717a31e  2023-06-15 21:17:36+00:00  b5058ddc   \n",
       "1       c2d93608  2023-06-15 21:04:07+00:00  4b288607   \n",
       "2       82369a19  2023-06-15 20:53:01+00:00  f328aa3d   \n",
       "3       e50bab11  2023-06-15 20:51:58+00:00  ea3b9f01   \n",
       "4       c00f39ee  2023-06-15 18:40:27+00:00  7d4d44e6   \n",
       "...          ...                        ...       ...   \n",
       "217648  def67d31  2023-06-18 09:54:34+00:00  e1888bba   \n",
       "217649  02a206ef  2023-06-16 14:09:26+00:00  a838dedb   \n",
       "217650  f17410cd  2023-06-15 12:15:25+00:00  62f322a1   \n",
       "217651  254011dc  2023-06-13 18:01:23+00:00  a7ebdbee   \n",
       "217652  470d58f7  2023-06-12 20:59:16+00:00  cafb9d63   \n",
       "\n",
       "                                                full_text  favorite_count  \\\n",
       "0         This is our chance to show our love for Lock...             0.0   \n",
       "1       Feeling very hopeful that with our worldwide c...             1.0   \n",
       "2         This is our chance to show our love for Lock...             0.0   \n",
       "3         ‼️Hey, LockNation! Here's the great idea!🔥 W...             0.0   \n",
       "4       Your daily reminder to vote and share! #VoteLo...             0.0   \n",
       "...                                                   ...             ...   \n",
       "217648        If anything will make me resubscribe to ...             2.0   \n",
       "217649   Yes, Alice! Lockwood and Co taking all the wi...             1.0   \n",
       "217650    #SaveLockwoodandCo  #LockwoodandCo #DisneySa...             0.0   \n",
       "217651    I FINALLY FINISHED IT, OH GHAD, BUT I PRESEN...             0.0   \n",
       "217652    Can anyone see our hashtags trending right n...             0.0   \n",
       "\n",
       "        retweet_count  retweet   week  \n",
       "0                18.0     True  week5  \n",
       "1                 0.0    False  week5  \n",
       "2                18.0     True  week5  \n",
       "3                 2.0     True  week5  \n",
       "4                 0.0    False  week5  \n",
       "...               ...      ...    ...  \n",
       "217648            0.0    False  week5  \n",
       "217649            0.0    False  week5  \n",
       "217650           16.0     True  week5  \n",
       "217651           26.0     True  week5  \n",
       "217652            3.0     True  week5  \n",
       "\n",
       "[143458 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df = working_df[['tweet_id', 'created_at', 'user', 'full_text', 'favorite_count', 'retweet_count', 'retweet', 'week']]\n",
    "working_df.to_csv('output/tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(hashtags_df['tweet_id'])==set(working_df['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove existing database if available\n",
    "if os.path.exists('output/lnctweets.db'):\n",
    "    os.remove('output/lnctweets.db')\n",
    "# Creating a database file for the all the output csv file\n",
    "# Establish a connection to the SQLite Database\n",
    "conn = sqlite3.connect('output/lnctweets.db')\n",
    "# Create a cursor object to execute SQL statements:\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create table based on the CSV file's columns\n",
    "def create_table(table_name, columns):\n",
    "    create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} ({', '.join(columns)})\"\n",
    "    cursor.execute(create_table_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to insert data into the table from a CSV file:\n",
    "def insert_data(table_name, csv_file):\n",
    "    with open(csv_file, 'r') as file:\n",
    "        csv_data = csv.reader(file)\n",
    "        next(csv_data)  # Skip the header row if necessary\n",
    "        insert_query = f\"INSERT INTO {table_name} VALUES ({', '.join(['?'] * len(next(csv_data)))})\"\n",
    "        cursor.executemany(insert_query, csv_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the CSV file paths and table names for each file:\n",
    "csv_files = ['output/hashtags.csv',  'output/tweets.csv', 'output/userinteraction.csv', 'output/username.csv']\n",
    "table_names = ['hashtags', 'tweets', 'userinteraction', 'username']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables and insert data for each CSV file:\n",
    "for i, csv_file in enumerate(csv_files):\n",
    "    table_name = table_name[i]\n",
    "    with open(csv_file, 'r') as file:\n",
    "        csv_data = csv.reader(file)\n",
    "        columns = next(csv_data)\n",
    "        create_table(table_name, columns)\n",
    "        insert_data(table_name, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the tweets table in the .db file\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM tweets\n",
    "    \"\"\"\n",
    "conn = sqlite3.connect('output/lnctweets.db')\n",
    "pd.read_sql_query(query,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimal_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
