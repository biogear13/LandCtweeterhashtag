{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import time\n",
    "import re\n",
    "import hashlib\n",
    "\n",
    "import sqlite3\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tokens\n",
    "config = configparser.ConfigParser()\n",
    "config.read('configfile.ini')\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "# authenticate\n",
    "auth = tweepy.OAuth2AppHandler(api_key, api_key_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_dataframe(working_df, tweets, hashtag):\n",
    "    #working_df=working_df.drop_duplicates()\n",
    "    print(f'working on {hashtag}')\n",
    "    index=len(working_df)\n",
    "    for tweet in tweets: \n",
    "        working_df.loc[index,'tweet_id']=tweet.id\n",
    "        working_df.loc[index,'created_at']=tweet.created_at\n",
    "        working_df.loc[index,'user']=tweet.user.screen_name\n",
    "        working_df.loc[index,'full_text']=tweet.full_text\n",
    "        working_df.loc[index,'favorite_count']=tweet.favorite_count\n",
    "        working_df.loc[index,'retweet_count']=tweet.retweet_count\n",
    "        working_df.loc[index,'hashtags']=hashtag\n",
    "        #print(working_df.loc[index,'created_at'])\n",
    "        #working_df=working_df.drop_duplicates()\n",
    "        index+=1\n",
    "        working_df.to_csv(f'source/{hashtag}.csv', index=False)\n",
    "        #time.sleep(1)\n",
    "    working_df=working_df.drop_duplicates()\n",
    "    working_df.to_csv(f'source/{hashtag}.csv', index=False)\n",
    "    working_df['created_at'] = pd.to_datetime(working_df['created_at'], utc=True)\n",
    "    # Group the DataFrame by day\n",
    "    grouped_df = working_df.groupby(pd.Grouper(key='created_at', freq='D'))\n",
    "\n",
    "    # Calculate the count of rows for each day\n",
    "    count_per_day = grouped_df['hashtags'].count()\n",
    "\n",
    "    # Display the count per day\n",
    "    print(count_per_day)\n",
    "          \n",
    "    return working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_from_general_tags(working_df, hashtag):\n",
    "    #load and merge the general_tags\n",
    "    print(f'working on {hashtag}')\n",
    "    general_tags = ['#SaveLockwoodandCo', 'Lockwood and Co']\n",
    "    general_tags_df=pd.DataFrame()\n",
    "    for tag in general_tags:\n",
    "        try:\n",
    "            general_tags_df=pd.concat([general_tags_df, pd.read_csv(f'source/{tag}.csv')], ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "    general_tags_df =general_tags_df.drop_duplicates()\n",
    "    print(f'total generaltags: {len(general_tags_df)}')\n",
    "    #general_tags_df['full_text'] = general_tags_df['full_text'].apply(lambda x: x.replace('\\n',' ').replace(':', ' '))\n",
    "    #Get the rows in the working_df that have the hashtag inside the full_text column\n",
    "    hashtag_df = general_tags_df[general_tags_df['full_text'].apply(lambda x: hashtag.lower() in x.lower())]\n",
    "    #hashtag_df = hashtag_df.reset_index(drop=True)\n",
    "    hashtag_df['hashtags'] = hashtag\n",
    "    working_df=pd.concat([working_df, hashtag_df], ignore_index=True)\n",
    "    working_df=working_df.drop_duplicates()\n",
    "    working_df['full_text'] = working_df['full_text'].apply(lambda x: x.replace('\\n',' ').replace(':', ' '))\n",
    "    working_df.to_csv(f'source/{hashtag}.csv', index=False)\n",
    "    working_df['created_at'] = pd.to_datetime(working_df['created_at'], utc=True)\n",
    "    # Group the DataFrame by day\n",
    "    grouped_df = working_df.groupby(pd.Grouper(key='created_at', freq='D'))\n",
    "\n",
    "    # Calculate the count of rows for each day\n",
    "    count_per_day = grouped_df['hashtags'].count()\n",
    "\n",
    "    # Display the count per day\n",
    "    print(count_per_day)\n",
    "  \n",
    "    return working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hash function to generate anonymized values\n",
    "def anonymize(value):\n",
    "    # Convert the value to a string and hash it using SHA256 algorithm\n",
    "    hashed_value = hashlib.sha256(str(value).encode()).hexdigest()\n",
    "    # Take the first 8 characters of the hash as the anonymized value\n",
    "    anonymized_value = hashed_value[:8]\n",
    "    return anonymized_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtagsweek1 = ['#FridayNightatPortlandRow', '#HauntedWatchParty', '#WatchPartyatPortlandRow', '#HauntedbyaType3','#TogetherForLockwoodandCo','#PrimeForLockwoodandCo','#BringBackLockwoodandCo']\n",
    "hashtagsweek2 = ['#GhostHuntersWatchParty', '#DisneyForLockwoodandCo', '#BBCforLockwoodandCo', '#AppleTVforLockwoodandCo', '#PrimeForLockwoodandCo', '#JustRecklessEnough']\n",
    "hashtagsweek3 = ['#LockwoodGhostAuditions', '#ParamountForLockwoodandCo', '#ScullandCo','#RapiersReady', '#CaringforCarlyle', '#DEPRACisOnTheWay', '#BunsForBunchurch']\n",
    "hashtagsweek4 = ['#CompleteFictionAppreciation', '#DisneySaveLockwood', '#ArtistryofLockwoodandCo', '#ParamountSaveLockwood', '#GhostStrike', '#LockwoodParallelFandoms', '#JustRecklessEnough']\n",
    "hashtagsweek5 = ['#StroudsAppreciation', '#VoteLockwoodforNFA', '#PrimeSaveLockwood', '#ScreamingStaircase', '#DEPRACrollcall', '#LivingforLockwood', '#RapiersReady']\n",
    "hashtagsweek6 = ['#LockNationAppreciation', '#LockNationArtistsandGiftsDay', '#LockNationEditorsDay', '#LockNationFicWritersDay', '#LockNationComediansDay', '#GhostLockAwards']\n",
    "hashtagsall = hashtagsweek1+hashtagsweek2+hashtagsweek3+hashtagsweek4 + hashtagsweek5\n",
    "hashtagsall = list(set(hashtagsall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16243\n",
      "working on Lockwood and Co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 157\n",
      "/tmp/ipykernel_899/1434055682.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  working_df['created_at'] = pd.to_datetime(working_df['created_at'], utc=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_at\n",
      "2023-06-02 00:00:00+00:00      64\n",
      "2023-06-03 00:00:00+00:00     313\n",
      "2023-06-04 00:00:00+00:00     275\n",
      "2023-06-05 00:00:00+00:00     443\n",
      "2023-06-06 00:00:00+00:00     725\n",
      "2023-06-07 00:00:00+00:00     922\n",
      "2023-06-08 00:00:00+00:00    1159\n",
      "2023-06-09 00:00:00+00:00    1710\n",
      "2023-06-10 00:00:00+00:00    1937\n",
      "2023-06-11 00:00:00+00:00    2756\n",
      "2023-06-12 00:00:00+00:00     407\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00    4878\n",
      "2023-06-16 00:00:00+00:00    4023\n",
      "2023-06-17 00:00:00+00:00    2049\n",
      "2023-06-18 00:00:00+00:00    2315\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "22673\n",
      "23976\n",
      "working on Lockwood and Co\n",
      "created_at\n",
      "2023-06-02 00:00:00+00:00      64\n",
      "2023-06-03 00:00:00+00:00     313\n",
      "2023-06-04 00:00:00+00:00     275\n",
      "2023-06-05 00:00:00+00:00     443\n",
      "2023-06-06 00:00:00+00:00     725\n",
      "2023-06-07 00:00:00+00:00     922\n",
      "2023-06-08 00:00:00+00:00    1159\n",
      "2023-06-09 00:00:00+00:00    1710\n",
      "2023-06-10 00:00:00+00:00    1937\n",
      "2023-06-11 00:00:00+00:00    2756\n",
      "2023-06-12 00:00:00+00:00     407\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00    6621\n",
      "2023-06-16 00:00:00+00:00    7429\n",
      "2023-06-17 00:00:00+00:00    5424\n",
      "2023-06-18 00:00:00+00:00    6069\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "28020\n"
     ]
    }
   ],
   "source": [
    "\n",
    "phrase = 'Lockwood and Co'\n",
    "try:\n",
    "    working_df = pd.read_csv(f'source/{phrase}.csv')\n",
    "    print(len(working_df))\n",
    "except:\n",
    "    working_df = pd.DataFrame(columns=['tweet_id', 'created_at', 'user', 'full_text', 'favorite_count', 'retweet_count', 'hashtags'])\n",
    "    \n",
    "tweets = tweepy.Cursor(api.search_tweets, q=phrase, tweet_mode='extended').items()\n",
    "working_df = get_tweets_dataframe(working_df, tweets, phrase)\n",
    "    \n",
    "working_df.drop_duplicates(inplace=True)\n",
    "print(len(working_df))\n",
    "    \n",
    "time.sleep(60)\n",
    "\n",
    "hashtag = '#SaveLockwoodandCo'\n",
    "try:\n",
    "    working_df = pd.read_csv(f'source/{phrase}.csv')\n",
    "    print(len(working_df))\n",
    "except:\n",
    "    working_df = pd.DataFrame(columns=['tweet_id', 'created_at', 'user', 'full_text', 'favorite_count', 'retweet_count', 'hashtags'])\n",
    "    \n",
    "tweets = tweepy.Cursor(api.search_tweets, q=hashtag, tweet_mode='extended').items()\n",
    "working_df = get_tweets_dataframe(working_df, tweets, phrase)\n",
    "    \n",
    "working_df.drop_duplicates(inplace=True)\n",
    "print(len(working_df))\n",
    "    \n",
    "time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n",
      "working on #LockNationAppreciation\n",
      "created_at\n",
      "2023-06-18 00:00:00+00:00       2\n",
      "2023-06-19 00:00:00+00:00    3723\n",
      "2023-06-20 00:00:00+00:00     628\n",
      "2023-06-21 00:00:00+00:00      23\n",
      "2023-06-22 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "4288\n",
      "0\n",
      "working on #LockNationArtistsandGiftsDay\n",
      "created_at\n",
      "2023-06-20 00:00:00+00:00    1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "1\n",
      "0\n",
      "working on #LockNationEditorsDay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_at\n",
      "2023-06-20 00:00:00+00:00      45\n",
      "2023-06-21 00:00:00+00:00    2905\n",
      "2023-06-22 00:00:00+00:00     490\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "3440\n",
      "0\n",
      "working on #LockNationFicWritersDay\n",
      "Series([], Freq: D, Name: hashtags, dtype: int64)\n",
      "0\n",
      "0\n",
      "working on #LockNationComediansDay\n",
      "Series([], Freq: D, Name: hashtags, dtype: int64)\n",
      "0\n",
      "0\n",
      "working on #GhostLockAwards\n",
      "Series([], Freq: D, Name: hashtags, dtype: int64)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "hashtags = ['#PrimeSaveLockwood']\n",
    "for hashtag in hashtagsweek6:\n",
    "    try:\n",
    "        working_df=pd.read_csv(f'source/{hashtag}.csv')\n",
    "        #working_df = pd.read_csv('source/#SkullandCo.csv')\n",
    "        print(len(working_df))\n",
    "    except:\n",
    "        working_df=pd.DataFrame(columns=['tweet_id','created_at', 'user', 'full_text','favorite_count','retweet_count','hashtags'])\n",
    "    tweets = tweepy.Cursor(api.search_tweets, q=hashtag, tweet_mode='extended').items()\n",
    "    working_df = get_tweets_dataframe(working_df, tweets, hashtag)\n",
    "    working_df=working_df.drop_duplicates()\n",
    "    print(len(working_df))\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try\n",
      "working on #ArtistryofLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-06 00:00:00+00:00      2\n",
      "2023-06-07 00:00:00+00:00    933\n",
      "2023-06-08 00:00:00+00:00    995\n",
      "2023-06-09 00:00:00+00:00     62\n",
      "2023-06-10 00:00:00+00:00     10\n",
      "2023-06-11 00:00:00+00:00     29\n",
      "2023-06-12 00:00:00+00:00      7\n",
      "2023-06-13 00:00:00+00:00      3\n",
      "2023-06-14 00:00:00+00:00      1\n",
      "2023-06-15 00:00:00+00:00      2\n",
      "2023-06-16 00:00:00+00:00      1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #LivingforLockwood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_712/2862647720.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hashtag_df['hashtags'] = hashtag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-16 00:00:00+00:00      38\n",
      "2023-06-17 00:00:00+00:00    5122\n",
      "2023-06-18 00:00:00+00:00    1059\n",
      "2023-06-19 00:00:00+00:00      23\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #WatchPartyatPortlandRow\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-20 00:00:00+00:00       1\n",
      "2023-05-21 00:00:00+00:00    3902\n",
      "2023-05-22 00:00:00+00:00    1243\n",
      "2023-05-23 00:00:00+00:00      92\n",
      "2023-05-24 00:00:00+00:00       8\n",
      "2023-05-25 00:00:00+00:00       1\n",
      "2023-05-26 00:00:00+00:00       0\n",
      "2023-05-27 00:00:00+00:00       0\n",
      "2023-05-28 00:00:00+00:00       2\n",
      "2023-05-29 00:00:00+00:00       0\n",
      "2023-05-30 00:00:00+00:00       3\n",
      "2023-05-31 00:00:00+00:00       0\n",
      "2023-06-01 00:00:00+00:00       2\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00       0\n",
      "2023-06-04 00:00:00+00:00       0\n",
      "2023-06-05 00:00:00+00:00       0\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #BringBackLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-15 00:00:00+00:00    3522\n",
      "2023-05-16 00:00:00+00:00    2649\n",
      "2023-05-17 00:00:00+00:00     854\n",
      "2023-05-18 00:00:00+00:00     346\n",
      "2023-05-19 00:00:00+00:00      92\n",
      "2023-05-20 00:00:00+00:00      31\n",
      "2023-05-21 00:00:00+00:00      45\n",
      "2023-05-22 00:00:00+00:00      23\n",
      "2023-05-23 00:00:00+00:00      22\n",
      "2023-05-24 00:00:00+00:00      21\n",
      "2023-05-25 00:00:00+00:00      13\n",
      "2023-05-26 00:00:00+00:00      17\n",
      "2023-05-27 00:00:00+00:00      14\n",
      "2023-05-28 00:00:00+00:00      19\n",
      "2023-05-29 00:00:00+00:00      21\n",
      "2023-05-30 00:00:00+00:00      28\n",
      "2023-05-31 00:00:00+00:00      21\n",
      "2023-06-01 00:00:00+00:00      28\n",
      "2023-06-02 00:00:00+00:00      11\n",
      "2023-06-03 00:00:00+00:00      12\n",
      "2023-06-04 00:00:00+00:00       7\n",
      "2023-06-05 00:00:00+00:00       1\n",
      "2023-06-06 00:00:00+00:00       1\n",
      "2023-06-07 00:00:00+00:00       4\n",
      "2023-06-08 00:00:00+00:00      14\n",
      "2023-06-09 00:00:00+00:00       6\n",
      "2023-06-10 00:00:00+00:00       2\n",
      "2023-06-11 00:00:00+00:00       4\n",
      "2023-06-12 00:00:00+00:00       2\n",
      "2023-06-13 00:00:00+00:00       5\n",
      "2023-06-14 00:00:00+00:00       4\n",
      "2023-06-15 00:00:00+00:00       2\n",
      "2023-06-16 00:00:00+00:00       8\n",
      "2023-06-17 00:00:00+00:00       2\n",
      "2023-06-18 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #BunsForBunchurch\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-29 00:00:00+00:00       7\n",
      "2023-05-30 00:00:00+00:00       2\n",
      "2023-05-31 00:00:00+00:00       2\n",
      "2023-06-01 00:00:00+00:00       1\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00      10\n",
      "2023-06-04 00:00:00+00:00    7890\n",
      "2023-06-05 00:00:00+00:00    1225\n",
      "2023-06-06 00:00:00+00:00      34\n",
      "2023-06-07 00:00:00+00:00      18\n",
      "2023-06-08 00:00:00+00:00      29\n",
      "2023-06-09 00:00:00+00:00      17\n",
      "2023-06-10 00:00:00+00:00      17\n",
      "2023-06-11 00:00:00+00:00      20\n",
      "2023-06-12 00:00:00+00:00       2\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       1\n",
      "2023-06-15 00:00:00+00:00       0\n",
      "2023-06-16 00:00:00+00:00       4\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #FridayNightatPortlandRow\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-18 00:00:00+00:00       3\n",
      "2023-05-19 00:00:00+00:00    3518\n",
      "2023-05-20 00:00:00+00:00    1363\n",
      "2023-05-21 00:00:00+00:00     196\n",
      "2023-05-22 00:00:00+00:00      53\n",
      "2023-05-23 00:00:00+00:00      17\n",
      "2023-05-24 00:00:00+00:00       8\n",
      "2023-05-25 00:00:00+00:00       1\n",
      "2023-05-26 00:00:00+00:00       0\n",
      "2023-05-27 00:00:00+00:00       6\n",
      "2023-05-28 00:00:00+00:00      15\n",
      "2023-05-29 00:00:00+00:00       3\n",
      "2023-05-30 00:00:00+00:00       0\n",
      "2023-05-31 00:00:00+00:00       1\n",
      "2023-06-01 00:00:00+00:00       4\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00       3\n",
      "2023-06-04 00:00:00+00:00       9\n",
      "2023-06-05 00:00:00+00:00       0\n",
      "2023-06-06 00:00:00+00:00       2\n",
      "2023-06-07 00:00:00+00:00       3\n",
      "2023-06-08 00:00:00+00:00       0\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00       1\n",
      "2023-06-12 00:00:00+00:00       2\n",
      "2023-06-13 00:00:00+00:00       1\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00       4\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #JustRecklessEnough\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-22 00:00:00+00:00      27\n",
      "2023-05-23 00:00:00+00:00       0\n",
      "2023-05-24 00:00:00+00:00       0\n",
      "2023-05-25 00:00:00+00:00       0\n",
      "2023-05-26 00:00:00+00:00      26\n",
      "2023-05-27 00:00:00+00:00    3242\n",
      "2023-05-28 00:00:00+00:00    4930\n",
      "2023-05-29 00:00:00+00:00    1575\n",
      "2023-05-30 00:00:00+00:00     149\n",
      "2023-05-31 00:00:00+00:00      19\n",
      "2023-06-01 00:00:00+00:00      22\n",
      "2023-06-02 00:00:00+00:00      14\n",
      "2023-06-03 00:00:00+00:00      14\n",
      "2023-06-04 00:00:00+00:00       4\n",
      "2023-06-05 00:00:00+00:00      13\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       0\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00      33\n",
      "2023-06-11 00:00:00+00:00    6371\n",
      "2023-06-12 00:00:00+00:00    2335\n",
      "2023-06-13 00:00:00+00:00      77\n",
      "2023-06-14 00:00:00+00:00       9\n",
      "2023-06-15 00:00:00+00:00       5\n",
      "2023-06-16 00:00:00+00:00       2\n",
      "2023-06-17 00:00:00+00:00       6\n",
      "2023-06-18 00:00:00+00:00       1\n",
      "2023-06-19 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #GhostStrike\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-08 00:00:00+00:00      11\n",
      "2023-06-09 00:00:00+00:00    4749\n",
      "2023-06-10 00:00:00+00:00    1455\n",
      "2023-06-11 00:00:00+00:00      93\n",
      "2023-06-12 00:00:00+00:00      26\n",
      "2023-06-13 00:00:00+00:00       1\n",
      "2023-06-14 00:00:00+00:00       3\n",
      "2023-06-15 00:00:00+00:00       6\n",
      "2023-06-16 00:00:00+00:00       1\n",
      "2023-06-17 00:00:00+00:00       4\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #VoteLockwoodforNFA\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-12 00:00:00+00:00      33\n",
      "2023-06-13 00:00:00+00:00    3453\n",
      "2023-06-14 00:00:00+00:00     683\n",
      "2023-06-15 00:00:00+00:00     106\n",
      "2023-06-16 00:00:00+00:00      71\n",
      "2023-06-17 00:00:00+00:00       4\n",
      "2023-06-18 00:00:00+00:00       3\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #BBCforLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-22 00:00:00+00:00      27\n",
      "2023-05-23 00:00:00+00:00       1\n",
      "2023-05-24 00:00:00+00:00    3881\n",
      "2023-05-25 00:00:00+00:00    1297\n",
      "2023-05-26 00:00:00+00:00     108\n",
      "2023-05-27 00:00:00+00:00      13\n",
      "2023-05-28 00:00:00+00:00      13\n",
      "2023-05-29 00:00:00+00:00      11\n",
      "2023-05-30 00:00:00+00:00       5\n",
      "2023-05-31 00:00:00+00:00       8\n",
      "2023-06-01 00:00:00+00:00       0\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00       3\n",
      "2023-06-04 00:00:00+00:00       2\n",
      "2023-06-05 00:00:00+00:00       3\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       3\n",
      "2023-06-09 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #ScullandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-31 00:00:00+00:00    1\n",
      "2023-06-01 00:00:00+00:00    2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #HauntedWatchParty\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-20 00:00:00+00:00    3433\n",
      "2023-05-21 00:00:00+00:00    1237\n",
      "2023-05-22 00:00:00+00:00     112\n",
      "2023-05-23 00:00:00+00:00      38\n",
      "2023-05-24 00:00:00+00:00       0\n",
      "2023-05-25 00:00:00+00:00       3\n",
      "2023-05-26 00:00:00+00:00       0\n",
      "2023-05-27 00:00:00+00:00      10\n",
      "2023-05-28 00:00:00+00:00       0\n",
      "2023-05-29 00:00:00+00:00       0\n",
      "2023-05-30 00:00:00+00:00       0\n",
      "2023-05-31 00:00:00+00:00       1\n",
      "2023-06-01 00:00:00+00:00       0\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00       2\n",
      "2023-06-04 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #HauntedbyaType3\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-16 00:00:00+00:00       1\n",
      "2023-05-17 00:00:00+00:00       0\n",
      "2023-05-18 00:00:00+00:00    4062\n",
      "2023-05-19 00:00:00+00:00    1555\n",
      "2023-05-20 00:00:00+00:00     143\n",
      "2023-05-21 00:00:00+00:00      33\n",
      "2023-05-22 00:00:00+00:00       4\n",
      "2023-05-23 00:00:00+00:00       6\n",
      "2023-05-24 00:00:00+00:00       1\n",
      "2023-05-25 00:00:00+00:00       1\n",
      "2023-05-26 00:00:00+00:00       0\n",
      "2023-05-27 00:00:00+00:00       0\n",
      "2023-05-28 00:00:00+00:00       0\n",
      "2023-05-29 00:00:00+00:00       0\n",
      "2023-05-30 00:00:00+00:00       2\n",
      "2023-05-31 00:00:00+00:00       1\n",
      "2023-06-01 00:00:00+00:00       1\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00       0\n",
      "2023-06-04 00:00:00+00:00       0\n",
      "2023-06-05 00:00:00+00:00       0\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       0\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00       0\n",
      "2023-06-12 00:00:00+00:00       0\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00       0\n",
      "2023-06-16 00:00:00+00:00       0\n",
      "2023-06-17 00:00:00+00:00       0\n",
      "2023-06-18 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #AppleTVforLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-22 00:00:00+00:00      27\n",
      "2023-05-23 00:00:00+00:00       1\n",
      "2023-05-24 00:00:00+00:00       3\n",
      "2023-05-25 00:00:00+00:00    3676\n",
      "2023-05-26 00:00:00+00:00     927\n",
      "2023-05-27 00:00:00+00:00      64\n",
      "2023-05-28 00:00:00+00:00      14\n",
      "2023-05-29 00:00:00+00:00       3\n",
      "2023-05-30 00:00:00+00:00       2\n",
      "2023-05-31 00:00:00+00:00       2\n",
      "2023-06-01 00:00:00+00:00      19\n",
      "2023-06-02 00:00:00+00:00       3\n",
      "2023-06-03 00:00:00+00:00       1\n",
      "2023-06-04 00:00:00+00:00       2\n",
      "2023-06-05 00:00:00+00:00       0\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       0\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00       0\n",
      "2023-06-12 00:00:00+00:00       0\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #DisneySaveLockwood\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-05 00:00:00+00:00      10\n",
      "2023-06-06 00:00:00+00:00    3778\n",
      "2023-06-07 00:00:00+00:00    1104\n",
      "2023-06-08 00:00:00+00:00     110\n",
      "2023-06-09 00:00:00+00:00       5\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00       7\n",
      "2023-06-12 00:00:00+00:00       1\n",
      "2023-06-13 00:00:00+00:00       1\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00       2\n",
      "2023-06-16 00:00:00+00:00       1\n",
      "2023-06-17 00:00:00+00:00       0\n",
      "2023-06-18 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #DEPRACrollcall\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-15 00:00:00+00:00      24\n",
      "2023-06-16 00:00:00+00:00    4503\n",
      "2023-06-17 00:00:00+00:00     504\n",
      "2023-06-18 00:00:00+00:00      37\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #CompleteFictionAppreciation\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-04 00:00:00+00:00       9\n",
      "2023-06-05 00:00:00+00:00    6708\n",
      "2023-06-06 00:00:00+00:00    1983\n",
      "2023-06-07 00:00:00+00:00      32\n",
      "2023-06-08 00:00:00+00:00       2\n",
      "2023-06-09 00:00:00+00:00       1\n",
      "2023-06-10 00:00:00+00:00       1\n",
      "2023-06-11 00:00:00+00:00       8\n",
      "2023-06-12 00:00:00+00:00      14\n",
      "2023-06-13 00:00:00+00:00      23\n",
      "2023-06-14 00:00:00+00:00       1\n",
      "2023-06-15 00:00:00+00:00      24\n",
      "2023-06-16 00:00:00+00:00      10\n",
      "2023-06-17 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #DEPRACisOnTheWay\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-02 00:00:00+00:00      42\n",
      "2023-06-03 00:00:00+00:00    4390\n",
      "2023-06-04 00:00:00+00:00     910\n",
      "2023-06-05 00:00:00+00:00      56\n",
      "2023-06-06 00:00:00+00:00       7\n",
      "2023-06-07 00:00:00+00:00       1\n",
      "2023-06-08 00:00:00+00:00       0\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00       4\n",
      "2023-06-12 00:00:00+00:00       0\n",
      "2023-06-13 00:00:00+00:00       1\n",
      "2023-06-14 00:00:00+00:00       2\n",
      "2023-06-15 00:00:00+00:00       0\n",
      "2023-06-16 00:00:00+00:00       4\n",
      "2023-06-17 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #TogetherForLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-16 00:00:00+00:00       3\n",
      "2023-05-17 00:00:00+00:00    6466\n",
      "2023-05-18 00:00:00+00:00    2568\n",
      "2023-05-19 00:00:00+00:00     242\n",
      "2023-05-20 00:00:00+00:00      23\n",
      "2023-05-21 00:00:00+00:00       7\n",
      "2023-05-22 00:00:00+00:00      15\n",
      "2023-05-23 00:00:00+00:00      10\n",
      "2023-05-24 00:00:00+00:00       8\n",
      "2023-05-25 00:00:00+00:00       8\n",
      "2023-05-26 00:00:00+00:00       4\n",
      "2023-05-27 00:00:00+00:00       4\n",
      "2023-05-28 00:00:00+00:00       4\n",
      "2023-05-29 00:00:00+00:00       0\n",
      "2023-05-30 00:00:00+00:00      10\n",
      "2023-05-31 00:00:00+00:00      11\n",
      "2023-06-01 00:00:00+00:00       5\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00       2\n",
      "2023-06-04 00:00:00+00:00       3\n",
      "2023-06-05 00:00:00+00:00       0\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       7\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00      13\n",
      "2023-06-12 00:00:00+00:00       0\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00       0\n",
      "2023-06-16 00:00:00+00:00       0\n",
      "2023-06-17 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #ParamountSaveLockwood\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-07 00:00:00+00:00       8\n",
      "2023-06-08 00:00:00+00:00    7329\n",
      "2023-06-09 00:00:00+00:00    1781\n",
      "2023-06-10 00:00:00+00:00      37\n",
      "2023-06-11 00:00:00+00:00      26\n",
      "2023-06-12 00:00:00+00:00       1\n",
      "2023-06-13 00:00:00+00:00       1\n",
      "2023-06-14 00:00:00+00:00       8\n",
      "2023-06-15 00:00:00+00:00       4\n",
      "2023-06-16 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #LockwoodParallelFandoms\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-07 00:00:00+00:00       1\n",
      "2023-06-08 00:00:00+00:00       0\n",
      "2023-06-09 00:00:00+00:00      23\n",
      "2023-06-10 00:00:00+00:00    5929\n",
      "2023-06-11 00:00:00+00:00    1713\n",
      "2023-06-12 00:00:00+00:00      75\n",
      "2023-06-13 00:00:00+00:00       4\n",
      "2023-06-14 00:00:00+00:00       1\n",
      "2023-06-15 00:00:00+00:00      10\n",
      "2023-06-16 00:00:00+00:00       0\n",
      "2023-06-17 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #CaringforCarlyle\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-28 00:00:00+00:00       1\n",
      "2023-05-29 00:00:00+00:00       1\n",
      "2023-05-30 00:00:00+00:00       0\n",
      "2023-05-31 00:00:00+00:00       0\n",
      "2023-06-01 00:00:00+00:00      16\n",
      "2023-06-02 00:00:00+00:00    4660\n",
      "2023-06-03 00:00:00+00:00    1514\n",
      "2023-06-04 00:00:00+00:00      65\n",
      "2023-06-05 00:00:00+00:00       4\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       2\n",
      "2023-06-08 00:00:00+00:00      11\n",
      "2023-06-09 00:00:00+00:00       1\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00       5\n",
      "2023-06-12 00:00:00+00:00       1\n",
      "2023-06-13 00:00:00+00:00       3\n",
      "2023-06-14 00:00:00+00:00       4\n",
      "2023-06-15 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #RapiersReady\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-28 00:00:00+00:00       1\n",
      "2023-05-29 00:00:00+00:00       0\n",
      "2023-05-30 00:00:00+00:00       0\n",
      "2023-05-31 00:00:00+00:00      39\n",
      "2023-06-01 00:00:00+00:00    5780\n",
      "2023-06-02 00:00:00+00:00    1421\n",
      "2023-06-03 00:00:00+00:00      36\n",
      "2023-06-04 00:00:00+00:00       3\n",
      "2023-06-05 00:00:00+00:00       1\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       2\n",
      "2023-06-08 00:00:00+00:00       9\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       0\n",
      "2023-06-11 00:00:00+00:00       3\n",
      "2023-06-12 00:00:00+00:00      10\n",
      "2023-06-13 00:00:00+00:00       1\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00       0\n",
      "2023-06-16 00:00:00+00:00       1\n",
      "2023-06-17 00:00:00+00:00      26\n",
      "2023-06-18 00:00:00+00:00    6207\n",
      "2023-06-19 00:00:00+00:00     545\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #ParamountForLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-28 00:00:00+00:00       1\n",
      "2023-05-29 00:00:00+00:00      38\n",
      "2023-05-30 00:00:00+00:00    7066\n",
      "2023-05-31 00:00:00+00:00    2501\n",
      "2023-06-01 00:00:00+00:00     144\n",
      "2023-06-02 00:00:00+00:00      15\n",
      "2023-06-03 00:00:00+00:00       8\n",
      "2023-06-04 00:00:00+00:00      12\n",
      "2023-06-05 00:00:00+00:00      12\n",
      "2023-06-06 00:00:00+00:00       4\n",
      "2023-06-07 00:00:00+00:00       6\n",
      "2023-06-08 00:00:00+00:00     110\n",
      "2023-06-09 00:00:00+00:00      12\n",
      "2023-06-10 00:00:00+00:00       4\n",
      "2023-06-11 00:00:00+00:00       2\n",
      "2023-06-12 00:00:00+00:00       0\n",
      "2023-06-13 00:00:00+00:00       2\n",
      "2023-06-14 00:00:00+00:00       4\n",
      "2023-06-15 00:00:00+00:00       3\n",
      "2023-06-16 00:00:00+00:00       2\n",
      "2023-06-17 00:00:00+00:00       4\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #PrimeForLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-14 00:00:00+00:00       1\n",
      "2023-05-15 00:00:00+00:00       3\n",
      "2023-05-16 00:00:00+00:00    5463\n",
      "2023-05-17 00:00:00+00:00    3167\n",
      "2023-05-18 00:00:00+00:00     331\n",
      "2023-05-19 00:00:00+00:00      76\n",
      "2023-05-20 00:00:00+00:00      36\n",
      "2023-05-21 00:00:00+00:00       3\n",
      "2023-05-22 00:00:00+00:00      32\n",
      "2023-05-23 00:00:00+00:00      14\n",
      "2023-05-24 00:00:00+00:00       4\n",
      "2023-05-25 00:00:00+00:00      43\n",
      "2023-05-26 00:00:00+00:00    4166\n",
      "2023-05-27 00:00:00+00:00    1609\n",
      "2023-05-28 00:00:00+00:00     122\n",
      "2023-05-29 00:00:00+00:00      33\n",
      "2023-05-30 00:00:00+00:00      25\n",
      "2023-05-31 00:00:00+00:00      27\n",
      "2023-06-01 00:00:00+00:00       5\n",
      "2023-06-02 00:00:00+00:00      15\n",
      "2023-06-03 00:00:00+00:00       8\n",
      "2023-06-04 00:00:00+00:00      14\n",
      "2023-06-05 00:00:00+00:00       1\n",
      "2023-06-06 00:00:00+00:00       4\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       9\n",
      "2023-06-09 00:00:00+00:00       7\n",
      "2023-06-10 00:00:00+00:00       2\n",
      "2023-06-11 00:00:00+00:00       0\n",
      "2023-06-12 00:00:00+00:00       0\n",
      "2023-06-13 00:00:00+00:00       1\n",
      "2023-06-14 00:00:00+00:00      12\n",
      "2023-06-15 00:00:00+00:00      10\n",
      "2023-06-16 00:00:00+00:00       0\n",
      "2023-06-17 00:00:00+00:00       0\n",
      "2023-06-18 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #StroudsAppreciation\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-11 00:00:00+00:00      16\n",
      "2023-06-12 00:00:00+00:00    2877\n",
      "2023-06-13 00:00:00+00:00     530\n",
      "2023-06-14 00:00:00+00:00      34\n",
      "2023-06-15 00:00:00+00:00      16\n",
      "2023-06-16 00:00:00+00:00       6\n",
      "2023-06-17 00:00:00+00:00       2\n",
      "2023-06-18 00:00:00+00:00       4\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #ScreamingStaircase\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-14 00:00:00+00:00       9\n",
      "2023-06-15 00:00:00+00:00    5850\n",
      "2023-06-16 00:00:00+00:00    1305\n",
      "2023-06-17 00:00:00+00:00       9\n",
      "2023-06-18 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #DisneyForLockwoodandCo\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-22 00:00:00+00:00      35\n",
      "2023-05-23 00:00:00+00:00    4179\n",
      "2023-05-24 00:00:00+00:00    1275\n",
      "2023-05-25 00:00:00+00:00     231\n",
      "2023-05-26 00:00:00+00:00      45\n",
      "2023-05-27 00:00:00+00:00       6\n",
      "2023-05-28 00:00:00+00:00      17\n",
      "2023-05-29 00:00:00+00:00      15\n",
      "2023-05-30 00:00:00+00:00       3\n",
      "2023-05-31 00:00:00+00:00      11\n",
      "2023-06-01 00:00:00+00:00       4\n",
      "2023-06-02 00:00:00+00:00       6\n",
      "2023-06-03 00:00:00+00:00       0\n",
      "2023-06-04 00:00:00+00:00       0\n",
      "2023-06-05 00:00:00+00:00       3\n",
      "2023-06-06 00:00:00+00:00      12\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       0\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       2\n",
      "2023-06-11 00:00:00+00:00       5\n",
      "2023-06-12 00:00:00+00:00       0\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00       0\n",
      "2023-06-16 00:00:00+00:00       2\n",
      "2023-06-17 00:00:00+00:00       5\n",
      "2023-06-18 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #LockwoodGhostAuditions\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-28 00:00:00+00:00      40\n",
      "2023-05-29 00:00:00+00:00    5292\n",
      "2023-05-30 00:00:00+00:00    1072\n",
      "2023-05-31 00:00:00+00:00      41\n",
      "2023-06-01 00:00:00+00:00      11\n",
      "2023-06-02 00:00:00+00:00       2\n",
      "2023-06-03 00:00:00+00:00       2\n",
      "2023-06-04 00:00:00+00:00       2\n",
      "2023-06-05 00:00:00+00:00       0\n",
      "2023-06-06 00:00:00+00:00       1\n",
      "2023-06-07 00:00:00+00:00       1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #PrimeSaveLockwood\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-06-09 00:00:00+00:00      2\n",
      "2023-06-10 00:00:00+00:00      0\n",
      "2023-06-11 00:00:00+00:00      0\n",
      "2023-06-12 00:00:00+00:00      0\n",
      "2023-06-13 00:00:00+00:00      0\n",
      "2023-06-14 00:00:00+00:00      0\n",
      "2023-06-15 00:00:00+00:00    658\n",
      "2023-06-16 00:00:00+00:00    106\n",
      "2023-06-17 00:00:00+00:00     13\n",
      "2023-06-18 00:00:00+00:00      9\n",
      "2023-06-19 00:00:00+00:00      2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #GhostHuntersWatchParty\n",
      "total generaltags: 77004\n",
      "created_at\n",
      "2023-05-21 00:00:00+00:00      11\n",
      "2023-05-22 00:00:00+00:00    3430\n",
      "2023-05-23 00:00:00+00:00     695\n",
      "2023-05-24 00:00:00+00:00      48\n",
      "2023-05-25 00:00:00+00:00      38\n",
      "2023-05-26 00:00:00+00:00       2\n",
      "2023-05-27 00:00:00+00:00       2\n",
      "2023-05-28 00:00:00+00:00       0\n",
      "2023-05-29 00:00:00+00:00       8\n",
      "2023-05-30 00:00:00+00:00       2\n",
      "2023-05-31 00:00:00+00:00       1\n",
      "2023-06-01 00:00:00+00:00       4\n",
      "2023-06-02 00:00:00+00:00       0\n",
      "2023-06-03 00:00:00+00:00       0\n",
      "2023-06-04 00:00:00+00:00       1\n",
      "2023-06-05 00:00:00+00:00       2\n",
      "2023-06-06 00:00:00+00:00       0\n",
      "2023-06-07 00:00:00+00:00       0\n",
      "2023-06-08 00:00:00+00:00       1\n",
      "2023-06-09 00:00:00+00:00       0\n",
      "2023-06-10 00:00:00+00:00       2\n",
      "2023-06-11 00:00:00+00:00       2\n",
      "Freq: D, Name: hashtags, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "hashtags = ['#SkullandCo']\n",
    "for hashtag in hashtagsall:\n",
    "    try:\n",
    "        \n",
    "        working_df=pd.read_csv(f'source/{hashtag}.csv')\n",
    "        print('try')\n",
    "        working_df = get_tweets_from_general_tags(working_df, hashtag)\n",
    "    except:\n",
    "        working_df=pd.DataFrame(columns=['tweet_id','created_at', 'user', 'full_text','favorite_count','retweet_count','hashtags'])\n",
    "        print('except')\n",
    "        working_df = get_tweets_from_general_tags(working_df, hashtag)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210522"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df=pd.DataFrame()\n",
    "for hashtag in hashtagsall:\n",
    "    try:\n",
    "        working_df=pd.concat([working_df, pd.read_csv(f'source/{hashtag}.csv')], ignore_index=True)\n",
    "    except:\n",
    "        pass\n",
    "len(working_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df['full_text'] = working_df['full_text'].str.replace(r'\"', '').replace(r'\\n', ' ').replace(':', ' ').replace(',', '').replace('!', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    116660\n",
       "True      93862\n",
       "Name: retweet, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column 'retweet' with default value False\n",
    "working_df['retweet'] = False\n",
    "\n",
    "# Check if 'full_text' starts with 'RT ' and set 'retweet' column accordingly\n",
    "working_df.loc[working_df['full_text'].str.startswith('RT '), 'retweet'] = True\n",
    "\n",
    "#Remove the 'RT ' in the full_text column\n",
    "working_df['full_text'] = working_df['full_text'].str.replace('RT ', '')\n",
    "\n",
    "working_df['retweet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_week_label(week_number):\n",
    "    if week_number == 20:\n",
    "        return 'week1'\n",
    "    elif week_number == 21:\n",
    "        return 'week2'\n",
    "    elif week_number == 22:\n",
    "        return 'week3'\n",
    "    elif week_number == 23:\n",
    "        return 'week4'\n",
    "    elif week_number == 24:\n",
    "        return 'week5'\n",
    "    elif week_number == 25:\n",
    "        return 'week6'\n",
    "    else:\n",
    "        return 'week1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "week4    47107\n",
       "week1    45386\n",
       "week3    45240\n",
       "week2    36116\n",
       "week5    36102\n",
       "week6      571\n",
       "Name: week, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df['created_date'] = pd.to_datetime(working_df['created_at'], utc=True)\n",
    "working_df['week'] = working_df['created_date'].dt.isocalendar().week\n",
    "working_df['week'] = working_df['week'].apply(get_week_label)\n",
    "working_df['week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an anonymized tweet_id\n",
    "#working_df['unique_id'] = str(working_df['tweet_id']) + working_df['created_at'] + working_df['user'] + str(working_df['retweet'])\n",
    "working_df['unique_id'] = working_df.apply(lambda row: str(row['tweet_id']) + row['created_at'] + row['user'] + str(row['retweet']), axis=1)\n",
    "working_df['tweet_id'] = working_df['unique_id'].apply(anonymize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hashtags\n",
       "#JustRecklessEnough             18875\n",
       "#PrimeForLockwoodandCo          15244\n",
       "#RapiersReady                   14085\n",
       "#ParamountForLockwoodandCo       9950\n",
       "#TogetherForLockwoodandCo        9415\n",
       "#BunsForBunchurch                9279\n",
       "#ParamountSaveLockwood           9196\n",
       "#CompleteFictionAppreciation     8818\n",
       "#BringBackLockwoodandCo          7853\n",
       "#LockwoodParallelFandoms         7758\n",
       "#ScreamingStaircase              7174\n",
       "#LockwoodGhostAuditions          6464\n",
       "#GhostStrike                     6349\n",
       "#CaringforCarlyle                6289\n",
       "#LivingforLockwood               6242\n",
       "#DisneyForLockwoodandCo          5858\n",
       "#HauntedbyaType3                 5811\n",
       "#DEPRACisOnTheWay                5419\n",
       "#BBCforLockwoodandCo             5377\n",
       "#WatchPartyatPortlandRow         5255\n",
       "#FridayNightatPortlandRow        5213\n",
       "#DEPRACrollcall                  5068\n",
       "#DisneySaveLockwood              5021\n",
       "#HauntedWatchParty               4838\n",
       "#AppleTVforLockwoodandCo         4746\n",
       "#VoteLockwoodforNFA              4353\n",
       "#GhostHuntersWatchParty          4249\n",
       "#StroudsAppreciation             3485\n",
       "#ArtistryofLockwoodandCo         2045\n",
       "#PrimeSaveLockwood                790\n",
       "#ScullandCo                         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags_df = working_df[['tweet_id','hashtags']]\n",
    "hashtags_df.to_csv('output/hashtags.csv', index=False)\n",
    "working_df.value_counts('hashtags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_712/3040538264.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  working_df['full_text'] = working_df['full_text'].str.replace(r'@(\\w+)', '')\n"
     ]
    }
   ],
   "source": [
    "# Get the tagged users from the full_text\n",
    "working_df=working_df.drop_duplicates('tweet_id')\n",
    "filter_out = ['@AppleSupport ','@AppleTV ','@AppleTVI ','@AppleTVPlus ','@AppleTVUK ','@BBC ', '@BBCOne ', '@BBCPlayer ','@BBCSounds ', '@BBCR1 ',\n",
    "            '@BBCSounds ','@BBCiPlayer ','@BBCone ','@D ','@Di ','@Dis ','@Disn ', '@Disne ', '@Dinsey ','@DisneyChannel ','@DisneyHyperion ','@DisneyIT ', '@DisneyPlus ', '@DisneyChannel ',\n",
    "            '@DisneyHyperion ','@DisneyPlusUK', '@DisneyPlus', '@HBO_UK ','@HBO ', '@hulu ','@NETFLIX ', '@netflix ', '@NETFLIXUK ', '@Netflix ', '@NetflixUK ','@ParamountPlus ', '@ParamaountUK ', '@ParamountPlusUK '\n",
    "            '@Prime ', '@PrimeUK ', '@PrimeVideo ', '@PrimeVideo','@primevideouk ']\n",
    "for filter in filter_out:\n",
    "    working_df['full_text'] = working_df['full_text'].str.replace(filter, '')\n",
    "working_df['tagged_users'] = working_df['full_text'].apply(lambda x: re.findall(r'@(\\w+)', x))\n",
    "# Remove the tagged users from the full_text\n",
    "working_df['full_text'] = working_df['full_text'].str.replace(r'@(\\w+)', '')\n",
    "list_of_tagged_users = []\n",
    "for x in range(len(working_df)):\n",
    "    try:\n",
    "        list_of_tagged_users += working_df['tagged_users'][x]\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a table for network analysis\n",
    "na_df = working_df[['tweet_id','user', 'retweet', 'tagged_users']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that would create a dataframe that shows the interaction\n",
    "def get_interaction(df):\n",
    "    func_df = pd.DataFrame(columns = ['tweet_id', 'from_', 'to_'])\n",
    "    filter_out = ['2','A','App','AppleSupport','AppleTV','AppleTVI','AppleTVPlus','AppleTVUK','BB','BBC','BBCO','BBC','BBCOn', 'BBCOne', 'BBCPlayer','BBCSounds', 'BBCR1',\n",
    "                  'BBCSounds','BBCiPlayer','BBCone','D','Di','Dis','Disn', 'Disne', 'Dinsey',' DisneyChannel','DisneyHyperion','DisneyIT', 'DisneyP', 'DisneyChannel',\n",
    "                  'DisneyHyperion','DisneyPlusUK', 'DisneyPlus', 'HBO', 'HBO_UK','NETFLIX', 'netflix', 'NETFLIXUK', 'Netflix', 'NetflixUK','ParamountPlus', 'ParamaountUK', 'ParamountPlusUK'\n",
    "                  'Prime', 'PrimeUK', 'PrimeVideo', 'primevideouk']\n",
    "    for x in range(len(df)):\n",
    "        if df['retweet'][0]=='True':\n",
    "            if df['tagged_users'].iloc[x][0] not in filter_out:\n",
    "                new_row = {'tweet_id':df['tweet_id'].iloc[x], 'from_':df['tagged_users'].iloc[x][0], 'to_': df['user'].iloc[x]}\n",
    "                func_df = func_df.append(new_row, ignore_index = True)\n",
    "            else:\n",
    "                print(df['tagged_users'].iloc[x][0])\n",
    "        else:\n",
    "            for user in df['tagged_users'].iloc[x]:\n",
    "                if user not in filter_out:\n",
    "                    new_row = {'tweet_id':df['tweet_id'].iloc[x], 'to_':user, 'from_': df['user'].iloc[x]}\n",
    "                    func_df = func_df.append(new_row, ignore_index = True)\n",
    "                else:\n",
    "                    print(user)\n",
    "    return func_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [tweet_id, from_, to_]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [tweet_id, from_, to_]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "filter_out = ['2','A','App','AppleSupport','AppleTV','AppleTVI','AppleTVPlus','AppleTVUK','BB','BBC','BBCO','BBC','BBCOn', 'BBCOne', 'BBCPlayer','BBCSounds', 'BBCR1',\n",
    "                  'BBCSounds','BBCiPlayer','BBCone','D','Di','Dis','Disn', 'Disne', 'Dinsey',' DisneyChannel','DisneyHyperion','DisneyIT', 'DisneyP', 'DisneyChannel',\n",
    "                  'DisneyHyperion','DisneyPlusUK', 'DisneyPlus', 'HBO', 'HBO_UK','NETFLIX', 'netflix', 'NETFLIXUK', 'Netflix', 'NetflixUK','ParamountPlus', 'ParamaountUK', 'ParamountPlusUK'\n",
    "                  'Prime', 'PrimeUK', 'PrimeVideo', 'primevideouk']\n",
    "na_interac_df = na_interac_df[~na_interac_df['from_'].isin(filter_out)]\n",
    "na_interac_df = na_interac_df[~na_interac_df['to_'].isin(filter_out)]                            \n",
    "print(na_interac_df[na_interac_df['from_'].isin(filter_out)])\n",
    "print(na_interac_df[na_interac_df['to_'].isin(filter_out)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a unique user dataframe\n",
    "list_of_user = na_interac_df['from_'].append(na_interac_df['to_'], ignore_index=True)\n",
    "list_of_user = list(set(list_of_user))\n",
    "user_df = pd.DataFrame(list_of_user, columns=['username'])\n",
    "user_df['user'] = user_df['username'].apply(anonymize)\n",
    "user_df=user_df.sort_values('username').reset_index()\n",
    "user_df.to_csv('output/username.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anonymise the users from the different dataframes\n",
    "na_interac_df['from_'] = na_interac_df['from_'].map(user_df.set_index('username')['user'])\n",
    "na_interac_df['to_'] = na_interac_df['to_'].map(user_df.set_index('username')['user'])\n",
    "working_df['user'] = working_df['user'].map(user_df.set_index('username')['user'])\n",
    "na_interac_df.to_csv('output/userinteraction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = working_df[['tweet_id', 'created_at', 'user', 'full_text', 'favorite_count', 'retweet_count', 'retweet', 'week']]\n",
    "working_df.to_csv('output/tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(hashtags_df['tweet_id'])==set(working_df['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove existing database if available\n",
    "if os.path.exists('output/lnctweets.db'):\n",
    "    os.remove('output/lnctweets.db')\n",
    "# Creating a database file for the all the output csv file\n",
    "# Establish a connection to the SQLite Database\n",
    "conn = sqlite3.connect('output/lnctweets.db')\n",
    "# Create a cursor object to execute SQL statements:\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(table_name, columns):\n",
    "    create_table_query = f\"CREATE TABLE IF NOT EXISTS `{table_name}` ({', '.join(columns)})\"\n",
    "    cursor.execute(create_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to insert data into the table from a CSV file:\n",
    "def insert_data(table_name, csv_file):\n",
    "    with open(csv_file, 'r') as file:\n",
    "        csv_data = csv.reader(file)\n",
    "        next(csv_data)  # Skip the header row if necessary\n",
    "        num_columns = len(next(csv_data))\n",
    "        insert_query = f\"INSERT INTO {table_name} VALUES ({', '.join(['?'] * num_columns)})\"\n",
    "        cursor.executemany(insert_query, csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the CSV file paths and table names for each file:\n",
    "csv_files = ['output/hashtags.csv',  'output/tweets.csv', 'output/userinteraction.csv']\n",
    "table_names = ['hashtags', 'tweets', 'userinteraction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables and insert data for each CSV file:\n",
    "for i, csv_file in enumerate(csv_files):\n",
    "    table_name = table_names[i]\n",
    "    with open(csv_file, 'r') as file:\n",
    "        csv_data = csv.reader(file)\n",
    "        columns = next(csv_data)\n",
    "        data_type = ' TEXT'\n",
    "        columns = [x + data_type for x in columns]\n",
    "        #print(columns)\n",
    "        create_table(table_name, columns)\n",
    "        insert_data(table_name, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        tweet_id     from_       to_\n",
      "0       6cbe5687  41c6f32a  fe802c03\n",
      "1       6cbe5687  41c6f32a  bdc181f0\n",
      "2       6cbe5687  41c6f32a  d4ced168\n",
      "3       6cbe5687  41c6f32a  20d15a56\n",
      "4       f8842111  0cfbd6ef  707e67d9\n",
      "...          ...       ...       ...\n",
      "141306  270964a5  6fc88075  20a79d68\n",
      "141307  4d269ca7  47994202  519ba526\n",
      "141308  dd27ac98  d8d26b48  ebcc1271\n",
      "141309  a6376cfa  432fc05e  d14c58ed\n",
      "141310  a6376cfa  432fc05e  20d15a56\n",
      "\n",
      "[141311 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# open the tweets table in the .db file\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM userinteraction\n",
    "    \"\"\"\n",
    "conn = sqlite3.connect('output/lnctweets.db')\n",
    "print(pd.read_sql_query(query,conn))\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimal_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
