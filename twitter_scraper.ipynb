{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import time\n",
    "import re\n",
    "import hashlib\n",
    "\n",
    "import sqlite3\n",
    "import csv\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tokens\n",
    "config = configparser.ConfigParser()\n",
    "config.read('configfile.ini')\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "# authenticate\n",
    "auth = tweepy.OAuth2AppHandler(api_key, api_key_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_dataframe(working_df, tweets, hashtag):\n",
    "    #working_df=working_df.drop_duplicates()\n",
    "    print(f'working on {hashtag}')\n",
    "    index=len(working_df)\n",
    "    for tweet in tweets: \n",
    "        working_df.loc[index,'tweet_id']=tweet.id\n",
    "        working_df.loc[index,'created_at']=tweet.created_at\n",
    "        working_df.loc[index,'user']=tweet.user.screen_name\n",
    "        working_df.loc[index,'full_text']=tweet.full_text\n",
    "        working_df.loc[index,'favorite_count']=tweet.favorite_count\n",
    "        working_df.loc[index,'retweet_count']=tweet.retweet_count\n",
    "        working_df.loc[index,'hashtags']=hashtag\n",
    "        #print(working_df.loc[index,'created_at'])\n",
    "        #working_df=working_df.drop_duplicates()\n",
    "        index+=1\n",
    "        working_df.to_csv(f'source/{hashtag}.csv', index=False)\n",
    "        #time.sleep(1)\n",
    "    working_df=working_df.drop_duplicates()\n",
    "    working_df.to_csv(f'source/{hashtag}.csv', index=False)\n",
    "    working_df['created_at'] = pd.to_datetime(working_df['created_at'], utc=True)\n",
    "    # Group the DataFrame by day\n",
    "    grouped_df = working_df.groupby(pd.Grouper(key='created_at', freq='D'))\n",
    "\n",
    "    # Calculate the count of rows for each day\n",
    "    count_per_day = grouped_df['hashtags'].count()\n",
    "\n",
    "    # Display the count per day\n",
    "    print(count_per_day)\n",
    "          \n",
    "    return working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_from_general_tags(working_df, hashtag):\n",
    "    #load and merge the general_tags\n",
    "    print(f'working on {hashtag}')\n",
    "    general_tags = ['#SaveLockwoodandCo', 'Lockwood and Co', 'Lockwood']\n",
    "    general_tags_df=pd.DataFrame()\n",
    "    for tag in general_tags:\n",
    "        try:\n",
    "            general_tags_df=pd.concat([general_tags_df, pd.read_csv(f'source/{tag}.csv')], ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "    general_tags_df =general_tags_df.drop_duplicates()\n",
    "    print(f'total generaltags: {len(general_tags_df)}')\n",
    "    #general_tags_df['full_text'] = general_tags_df['full_text'].apply(lambda x: x.replace('\\n',' ').replace(':', ' '))\n",
    "    #Get the rows in the working_df that have the hashtag inside the full_text column\n",
    "    hashtag_df = general_tags_df[general_tags_df['full_text'].apply(lambda x: hashtag.lower() in x.lower())]\n",
    "    #hashtag_df = hashtag_df.reset_index(drop=True)\n",
    "    hashtag_df['hashtags'] = hashtag\n",
    "    working_df=pd.concat([working_df, hashtag_df], ignore_index=True)\n",
    "    working_df=working_df.drop_duplicates()\n",
    "    working_df['full_text'] = working_df['full_text'].apply(lambda x: x.replace('\\n',' ').replace(':', ' '))\n",
    "    working_df.to_csv(f'source/{hashtag}.csv', index=False)\n",
    "    working_df['created_at'] = pd.to_datetime(working_df['created_at'], utc=True)\n",
    "    # Group the DataFrame by day\n",
    "    grouped_df = working_df.groupby(pd.Grouper(key='created_at', freq='D'))\n",
    "\n",
    "    # Calculate the count of rows for each day\n",
    "    count_per_day = grouped_df['hashtags'].count()\n",
    "\n",
    "    # Display the count per day\n",
    "    print(count_per_day)\n",
    "  \n",
    "    return working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hash function to generate anonymized values\n",
    "def anonymize(value):\n",
    "    # Convert the value to a string and hash it using SHA256 algorithm\n",
    "    hashed_value = hashlib.sha256(str(value).encode()).hexdigest()\n",
    "    # Take the first 8 characters of the hash as the anonymized value\n",
    "    anonymized_value = hashed_value[:8]\n",
    "    return anonymized_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtagsweek1 = ['#FridayNightatPortlandRow', '#HauntedWatchParty', '#WatchPartyatPortlandRow', '#HauntedbyaType3','#TogetherForLockwoodandCo','#PrimeForLockwoodandCo','#BringBackLockwoodandCo']\n",
    "hashtagsweek2 = ['#GhostHuntersWatchParty', '#DisneyForLockwoodandCo', '#BBCforLockwoodandCo', '#AppleTVforLockwoodandCo', '#PrimeForLockwoodandCo', '#JustRecklessEnough']\n",
    "hashtagsweek3 = ['#LockwoodGhostAuditions', '#ParamountForLockwoodandCo', '#ScullandCo','#RapiersReady', '#CaringforCarlyle', '#DEPRACisOnTheWay', '#BunsForBunchurch']\n",
    "hashtagsweek4 = ['#CompleteFictionAppreciation', '#DisneySaveLockwood', '#ArtistryofLockwoodandCo', '#ParamountSaveLockwood', '#GhostStrike', '#LockwoodParallelFandoms', '#JustRecklessEnough']\n",
    "hashtagsweek5 = ['#StroudsAppreciation', '#VoteLockwoodforNFA', '#PrimeSaveLockwood', '#ScreamingStaircase', '#DEPRACrollcall', '#LivingforLockwood', '#RapiersReady']\n",
    "hashtagsweek6 = ['#LockNationAppreciation', '#LockNationArtistsandGiftsDay', '#LockNationEditorsDay', '#LockNationFicWritersDay', '#LockNationComediansDay', '#GhostLockAwards']\n",
    "hashtagsweek7 = ['VoteLocwoodforNFA', '#LockwoodCastAppreciation', '#YouMeAndHerons', '#FishAndKipps', '#LockwoodDnDCampaign', '#TheIronTrio', '#VirtualThinkingCloth']\n",
    "hashtagsall = hashtagsweek1+hashtagsweek2+hashtagsweek3+hashtagsweek4 + hashtagsweek5 + hashtagsweek6 + hashtagsweek7\n",
    "hashtagsall = list(set(hashtagsall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36254\n",
      "working on Lockwood and Co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_786/3429170079.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  working_df['created_at'] = pd.to_datetime(working_df['created_at'], utc=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_at\n",
      "2023-06-02 00:00:00+00:00      64\n",
      "2023-06-03 00:00:00+00:00     313\n",
      "2023-06-04 00:00:00+00:00     275\n",
      "2023-06-05 00:00:00+00:00     443\n",
      "2023-06-06 00:00:00+00:00     725\n",
      "2023-06-07 00:00:00+00:00     922\n",
      "2023-06-08 00:00:00+00:00    1159\n",
      "2023-06-09 00:00:00+00:00    1710\n",
      "2023-06-10 00:00:00+00:00    1937\n",
      "2023-06-11 00:00:00+00:00    2756\n",
      "2023-06-12 00:00:00+00:00     407\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00    3956\n",
      "2023-06-16 00:00:00+00:00    5286\n",
      "2023-06-17 00:00:00+00:00    3615\n",
      "2023-06-18 00:00:00+00:00    3940\n",
      "2023-06-19 00:00:00+00:00       0\n",
      "2023-06-20 00:00:00+00:00       0\n",
      "2023-06-21 00:00:00+00:00       0\n",
      "2023-06-22 00:00:00+00:00       0\n",
      "2023-06-23 00:00:00+00:00       0\n",
      "2023-06-24 00:00:00+00:00     379\n",
      "2023-06-25 00:00:00+00:00    1614\n",
      "2023-06-26 00:00:00+00:00      14\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "29515\n",
      "29515\n",
      "working on Lockwood and Co\n",
      "created_at\n",
      "2023-06-02 00:00:00+00:00      64\n",
      "2023-06-03 00:00:00+00:00     313\n",
      "2023-06-04 00:00:00+00:00     275\n",
      "2023-06-05 00:00:00+00:00     443\n",
      "2023-06-06 00:00:00+00:00     725\n",
      "2023-06-07 00:00:00+00:00     922\n",
      "2023-06-08 00:00:00+00:00    1159\n",
      "2023-06-09 00:00:00+00:00    1710\n",
      "2023-06-10 00:00:00+00:00    1937\n",
      "2023-06-11 00:00:00+00:00    2756\n",
      "2023-06-12 00:00:00+00:00     407\n",
      "2023-06-13 00:00:00+00:00       0\n",
      "2023-06-14 00:00:00+00:00       0\n",
      "2023-06-15 00:00:00+00:00    3956\n",
      "2023-06-16 00:00:00+00:00    5286\n",
      "2023-06-17 00:00:00+00:00    3615\n",
      "2023-06-18 00:00:00+00:00    3940\n",
      "2023-06-19 00:00:00+00:00       0\n",
      "2023-06-20 00:00:00+00:00       0\n",
      "2023-06-21 00:00:00+00:00       0\n",
      "2023-06-22 00:00:00+00:00       0\n",
      "2023-06-23 00:00:00+00:00       0\n",
      "2023-06-24 00:00:00+00:00    2524\n",
      "2023-06-25 00:00:00+00:00    4194\n",
      "2023-06-26 00:00:00+00:00      36\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "32494\n"
     ]
    }
   ],
   "source": [
    "\n",
    "phrase = 'Lockwood and Co'\n",
    "try:\n",
    "    working_df = pd.read_csv(f'source/{phrase}.csv')\n",
    "    print(len(working_df))\n",
    "except:\n",
    "    working_df = pd.DataFrame(columns=['tweet_id', 'created_at', 'user', 'full_text', 'favorite_count', 'retweet_count', 'hashtags'])\n",
    "    \n",
    "tweets = tweepy.Cursor(api.search_tweets, q=phrase, tweet_mode='extended').items()\n",
    "working_df = get_tweets_dataframe(working_df, tweets, phrase)\n",
    "    \n",
    "working_df.drop_duplicates(inplace=True)\n",
    "print(len(working_df))\n",
    "    \n",
    "time.sleep(60)\n",
    "\n",
    "hashtag = '#SaveLockwoodandCo'\n",
    "try:\n",
    "    working_df = pd.read_csv(f'source/{phrase}.csv')\n",
    "    print(len(working_df))\n",
    "except:\n",
    "    working_df = pd.DataFrame(columns=['tweet_id', 'created_at', 'user', 'full_text', 'favorite_count', 'retweet_count', 'hashtags'])\n",
    "    \n",
    "tweets = tweepy.Cursor(api.search_tweets, q=hashtag, tweet_mode='extended').items()\n",
    "working_df = get_tweets_dataframe(working_df, tweets, phrase)\n",
    "    \n",
    "working_df.drop_duplicates(inplace=True)\n",
    "print(len(working_df))\n",
    "    \n",
    "time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on Lockwood\n",
      "created_at\n",
      "2023-06-26 00:00:00+00:00    149\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "phrase = 'Lockwood'\n",
    "try:\n",
    "    working_df = pd.read_csv(f'source/{phrase}.csv')\n",
    "    print(len(working_df))\n",
    "except:\n",
    "    working_df = pd.DataFrame(columns=['tweet_id', 'created_at', 'user', 'full_text', 'favorite_count', 'retweet_count', 'hashtags'])\n",
    "    \n",
    "tweets = tweepy.Cursor(api.search_tweets, q=phrase, tweet_mode='extended').items()\n",
    "working_df = get_tweets_dataframe(working_df, tweets, phrase)\n",
    "    \n",
    "working_df.drop_duplicates(inplace=True)\n",
    "print(len(working_df))\n",
    "    \n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "working on #LockNationArtistsandGiftsDay\n",
      "created_at\n",
      "2023-06-20 00:00:00+00:00    2\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "hashtags = ['#LockNationArtistsandGiftsDay']\n",
    "for hashtag in hashtags:\n",
    "    try:\n",
    "        working_df=pd.read_csv(f'source/{hashtag}.csv')\n",
    "        #working_df = pd.read_csv('source/#SkullandCo.csv')\n",
    "        print(len(working_df))\n",
    "    except:\n",
    "        working_df=pd.DataFrame(columns=['tweet_id','created_at', 'user', 'full_text','favorite_count','retweet_count','hashtags'])\n",
    "    tweets = tweepy.Cursor(api.search_tweets, q=hashtag, tweet_mode='extended').items()\n",
    "    working_df = get_tweets_dataframe(working_df, tweets, hashtag)\n",
    "    working_df=working_df.drop_duplicates()\n",
    "    print(len(working_df))\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try\n",
      "working on #LockNationAppreciation\n",
      "total generaltags: 81883\n",
      "created_at\n",
      "2023-06-18 00:00:00+00:00       4\n",
      "2023-06-19 00:00:00+00:00    3670\n",
      "2023-06-20 00:00:00+00:00    1174\n",
      "2023-06-21 00:00:00+00:00      66\n",
      "2023-06-22 00:00:00+00:00       8\n",
      "2023-06-23 00:00:00+00:00       4\n",
      "2023-06-24 00:00:00+00:00       0\n",
      "2023-06-25 00:00:00+00:00      20\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #LockNationArtistsandGiftsDay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_786/2862647720.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hashtag_df['hashtags'] = hashtag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total generaltags: 81883\n",
      "created_at\n",
      "2023-06-20 00:00:00+00:00    1\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #LockNationEditorsDay\n",
      "total generaltags: 81883\n",
      "created_at\n",
      "2023-06-20 00:00:00+00:00      45\n",
      "2023-06-21 00:00:00+00:00    5148\n",
      "2023-06-22 00:00:00+00:00    1187\n",
      "2023-06-23 00:00:00+00:00      51\n",
      "2023-06-24 00:00:00+00:00       4\n",
      "2023-06-25 00:00:00+00:00       4\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #LockNationFicWritersDay\n",
      "total generaltags: 81883\n",
      "created_at\n",
      "2023-06-23 00:00:00+00:00    3299\n",
      "2023-06-24 00:00:00+00:00     479\n",
      "2023-06-25 00:00:00+00:00      14\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #LockNationComediansDay\n",
      "total generaltags: 81883\n",
      "created_at\n",
      "2023-06-24 00:00:00+00:00    2894\n",
      "2023-06-25 00:00:00+00:00     804\n",
      "2023-06-26 00:00:00+00:00      12\n",
      "Freq: D, Name: hashtags, dtype: int64\n",
      "try\n",
      "working on #GhostLockAwards\n",
      "total generaltags: 81883\n",
      "created_at\n",
      "2023-06-25 00:00:00+00:00    4107\n",
      "2023-06-26 00:00:00+00:00     495\n",
      "Freq: D, Name: hashtags, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "hashtags = ['#SkullandCo']\n",
    "for hashtag in hashtagsweek6:\n",
    "    try:\n",
    "        \n",
    "        working_df=pd.read_csv(f'source/{hashtag}.csv')\n",
    "        print('try')\n",
    "        working_df = get_tweets_from_general_tags(working_df, hashtag)\n",
    "    except:\n",
    "        working_df=pd.DataFrame(columns=['tweet_id','created_at', 'user', 'full_text','favorite_count','retweet_count','hashtags'])\n",
    "        print('except')\n",
    "        working_df = get_tweets_from_general_tags(working_df, hashtag)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227730"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df=pd.DataFrame()\n",
    "for hashtag in hashtagsall:\n",
    "    try:\n",
    "        working_df=pd.concat([working_df, pd.read_csv(f'source/{hashtag}.csv')], ignore_index=True)\n",
    "    except:\n",
    "        pass\n",
    "len(working_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df['full_text'] = working_df['full_text'].str.replace(r'\"', '').replace(r'\\n', ' ').replace(':', ' ').replace(',', '').replace('!', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    128901\n",
       "True      98829\n",
       "Name: retweet, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column 'retweet' with default value False\n",
    "working_df['retweet'] = False\n",
    "\n",
    "# Check if 'full_text' starts with 'RT ' and set 'retweet' column accordingly\n",
    "working_df.loc[working_df['full_text'].str.startswith('RT '), 'retweet'] = True\n",
    "\n",
    "#Remove the 'RT ' in the full_text column\n",
    "working_df['full_text'] = working_df['full_text'].str.replace('RT ', '')\n",
    "\n",
    "working_df['retweet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_week_label(week_number):\n",
    "    if week_number == 20:\n",
    "        return 'week1'\n",
    "    elif week_number == 21:\n",
    "        return 'week2'\n",
    "    elif week_number == 22:\n",
    "        return 'week3'\n",
    "    elif week_number == 23:\n",
    "        return 'week4'\n",
    "    elif week_number == 24:\n",
    "        return 'week5'\n",
    "    elif week_number == 25:\n",
    "        return 'week6'\n",
    "    else:\n",
    "        return 'week1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "week4    47107\n",
       "week1    45695\n",
       "week3    45254\n",
       "week5    37164\n",
       "week2    36116\n",
       "week6    16394\n",
       "Name: week, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df['created_date'] = pd.to_datetime(working_df['created_at'], utc=True)\n",
    "working_df['week'] = working_df['created_date'].dt.isocalendar().week\n",
    "working_df['week'] = working_df['week'].apply(get_week_label)\n",
    "working_df['week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an anonymized tweet_id\n",
    "#working_df['unique_id'] = str(working_df['tweet_id']) + working_df['created_at'] + working_df['user'] + str(working_df['retweet'])\n",
    "working_df['unique_id'] = working_df.apply(lambda row: str(row['tweet_id']) + row['created_at'] + row['user'] + str(row['retweet']), axis=1)\n",
    "working_df['tweet_id'] = working_df['unique_id'].apply(anonymize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hashtags\n",
       "#JustRecklessEnough              18885\n",
       "#PrimeForLockwoodandCo           15252\n",
       "#RapiersReady                    15224\n",
       "#ParamountForLockwoodandCo        9958\n",
       "#TogetherForLockwoodandCo         9416\n",
       "#BunsForBunchurch                 9283\n",
       "#ParamountSaveLockwood            9196\n",
       "#CompleteFictionAppreciation      8824\n",
       "#BringBackLockwoodandCo           7874\n",
       "#LockwoodParallelFandoms          7759\n",
       "#ScreamingStaircase               7198\n",
       "#LivingforLockwood                6494\n",
       "#LockwoodGhostAuditions           6465\n",
       "#GhostStrike                      6350\n",
       "#CaringforCarlyle                 6289\n",
       "#DisneyForLockwoodandCo           5866\n",
       "#HauntedbyaType3                  5811\n",
       "#DEPRACisOnTheWay                 5425\n",
       "#BBCforLockwoodandCo              5380\n",
       "#WatchPartyatPortlandRow          5255\n",
       "#FridayNightatPortlandRow         5216\n",
       "#DEPRACrollcall                   5170\n",
       "#DisneySaveLockwood               5022\n",
       "#HauntedWatchParty                4838\n",
       "#AppleTVforLockwoodandCo          4748\n",
       "#LockNationAppreciation           4378\n",
       "#VoteLockwoodforNFA               4375\n",
       "#LockNationEditorsDay             4262\n",
       "#GhostHuntersWatchParty           4252\n",
       "#StroudsAppreciation              3487\n",
       "#GhostLockAwards                  2574\n",
       "#LockNationFicWritersDay          2205\n",
       "#LockNationComediansDay           2111\n",
       "#ArtistryofLockwoodandCo          2051\n",
       "#PrimeSaveLockwood                 819\n",
       "#FishAndKipps                       14\n",
       "#ScullandCo                          3\n",
       "#LockNationArtistsandGiftsDay        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags_df = working_df[['tweet_id','hashtags']]\n",
    "hashtags_df.to_csv('output/hashtags.csv', index=False)\n",
    "working_df.value_counts('hashtags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_786/3040538264.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  working_df['full_text'] = working_df['full_text'].str.replace(r'@(\\w+)', '')\n"
     ]
    }
   ],
   "source": [
    "# Get the tagged users from the full_text\n",
    "working_df=working_df.drop_duplicates('tweet_id')\n",
    "filter_out = ['@AppleSupport ','@AppleTV ','@AppleTVI ','@AppleTVPlus ','@AppleTVUK ','@BBC ', '@BBCOne ', '@BBCPlayer ','@BBCSounds ', '@BBCR1 ',\n",
    "            '@BBCSounds ','@BBCiPlayer ','@BBCone ','@D ','@Di ','@Dis ','@Disn ', '@Disne ', '@Dinsey ','@DisneyChannel ','@DisneyHyperion ','@DisneyIT ', '@DisneyPlus ', '@DisneyChannel ',\n",
    "            '@DisneyHyperion ','@DisneyPlusUK', '@DisneyPlus', '@HBO_UK ','@HBO ', '@hulu ','@NETFLIX ', '@netflix ', '@NETFLIXUK ', '@Netflix ', '@NetflixUK ','@ParamountPlus ', '@ParamaountUK ', '@ParamountPlusUK '\n",
    "            '@Prime ', '@PrimeUK ', '@PrimeVideo ', '@PrimeVideo','@primevideouk ']\n",
    "for filter in filter_out:\n",
    "    working_df['full_text'] = working_df['full_text'].str.replace(filter, '')\n",
    "working_df['tagged_users'] = working_df['full_text'].apply(lambda x: re.findall(r'@(\\w+)', x))\n",
    "# Remove the tagged users from the full_text\n",
    "working_df['full_text'] = working_df['full_text'].str.replace(r'@(\\w+)', '')\n",
    "list_of_tagged_users = []\n",
    "for x in range(len(working_df)):\n",
    "    try:\n",
    "        list_of_tagged_users += working_df['tagged_users'][x]\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a table for network analysis\n",
    "na_df = working_df[['tweet_id','user', 'retweet', 'tagged_users']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that would create a dataframe that shows the interaction\n",
    "def get_interaction(df):\n",
    "    func_df = pd.DataFrame(columns = ['tweet_id', 'from_', 'to_'])\n",
    "    filter_out = ['2','A','App','AppleSupport','AppleTV','AppleTVI','AppleTVPlus','AppleTVUK','BB','BBC','BBCO','BBC','BBCOn', 'BBCOne', 'BBCPlayer','BBCSounds', 'BBCR1',\n",
    "                  'BBCSounds','BBCiPlayer','BBCone','D','Di','Dis','Disn', 'Disne', 'Dinsey',' DisneyChannel','DisneyHyperion','DisneyIT', 'DisneyP', 'DisneyChannel',\n",
    "                  'DisneyHyperion','DisneyPlusUK', 'DisneyPlus', 'HBO', 'HBO_UK','NETFLIX', 'netflix', 'NETFLIXUK', 'Netflix', 'NetflixUK','ParamountPlus', 'ParamaountUK', 'ParamountPlusUK'\n",
    "                  'Prime', 'PrimeUK', 'PrimeVideo', 'primevideouk']\n",
    "    for x in range(len(df)):\n",
    "        if df['retweet'][0]=='True':\n",
    "            if df['tagged_users'].iloc[x][0] not in filter_out:\n",
    "                new_row = {'tweet_id':df['tweet_id'].iloc[x], 'from_':df['tagged_users'].iloc[x][0], 'to_': df['user'].iloc[x]}\n",
    "                func_df = func_df.append(new_row, ignore_index = True)\n",
    "            else:\n",
    "                print(df['tagged_users'].iloc[x][0])\n",
    "        else:\n",
    "            for user in df['tagged_users'].iloc[x]:\n",
    "                if user not in filter_out:\n",
    "                    new_row = {'tweet_id':df['tweet_id'].iloc[x], 'to_':user, 'from_': df['user'].iloc[x]}\n",
    "                    func_df = func_df.append(new_row, ignore_index = True)\n",
    "                else:\n",
    "                    print(user)\n",
    "    return func_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AppleTV\n",
      "netflix\n",
      "App\n",
      "Disne\n",
      "BBCOn\n",
      "netflix\n",
      "DisneyP\n",
      "DisneyP\n",
      "DisneyP\n",
      "netflix\n",
      "App\n",
      "netflix\n",
      "App\n",
      "netflix\n",
      "App\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NETFLIXUK\n",
      "netflix\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "Dis\n",
      "Dis\n",
      "Dis\n",
      "Dis\n",
      "Dis\n",
      "Dis\n",
      "primevideouk\n",
      "netflix\n",
      "NetflixUK\n",
      "BBC\n",
      "netflix\n",
      "netflix\n",
      "NetflixUK\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "NetflixUK\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "Netflix\n",
      "NetflixUK\n",
      "netflix\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "primevideouk\n",
      "NetflixUK\n",
      "BBC\n",
      "NetflixUK\n",
      "netflix\n",
      "NetflixUK\n",
      "Netflix\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "Disn\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "Disn\n",
      "netflix\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "primevideouk\n",
      "NetflixUK\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "NetflixUK\n",
      "netflix\n",
      "D\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "NetflixUK\n",
      "netflix\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "D\n",
      "netflix\n",
      "Disne\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "D\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "NetflixUK\n",
      "Disne\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "Disne\n",
      "netflix\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "NetflixUK\n",
      "primevideouk\n",
      "NetflixUK\n",
      "primevideouk\n",
      "primevideouk\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "D\n",
      "D\n",
      "D\n",
      "Disne\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "netflix\n",
      "Disne\n",
      "netflix\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "primevideouk\n",
      "Dis\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "primevideouk\n",
      "AppleTV\n",
      "DisneyP\n",
      "AppleTV\n",
      "DisneyP\n",
      "DisneyP\n",
      "DisneyP\n",
      "DisneyP\n",
      "DisneyP\n",
      "DisneyP\n",
      "DisneyP\n",
      "Netflix\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "D\n",
      "D\n",
      "D\n",
      "BBCOn\n",
      "BBCO\n",
      "BBCO\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCO\n",
      "BBC\n",
      "BBCOne\n",
      "BBCO\n",
      "primevideouk\n",
      "BBCO\n",
      "BBCO\n",
      "BBCO\n",
      "BBCO\n",
      "BBCO\n",
      "BBCO\n",
      "BBCO\n",
      "BBCO\n",
      "BBCO\n",
      "BBCO\n",
      "BBCO\n",
      "BBCO\n",
      "BBCO\n",
      "BBCOne\n",
      "BBCO\n",
      "BBCOn\n",
      "BBCO\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCO\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCO\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCO\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BB\n",
      "BBCO\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCO\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOn\n",
      "BBCOne\n",
      "BBCO\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "AppleTV\n",
      "BBCOn\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOn\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BB\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOn\n",
      "BBCOne\n",
      "BBCOn\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCO\n",
      "BBCOn\n",
      "BBC\n",
      "BBCOn\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBC\n",
      "BBCO\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBC\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBC\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBC\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCO\n",
      "BBC\n",
      "BBC\n",
      "BBC\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCO\n",
      "BBCO\n",
      "BBC\n",
      "BBCO\n",
      "BBCO\n",
      "BBCO\n",
      "BBCO\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCO\n",
      "BBCO\n",
      "BBCOne\n",
      "BBCO\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BB\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BB\n",
      "BBCOne\n",
      "NetflixUK\n",
      "BBCOne\n",
      "BBC\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "netflix\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBC\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BB\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "NetflixUK\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BB\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BB\n",
      "BB\n",
      "BBCOne\n",
      "BB\n",
      "BB\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBC\n",
      "BBC\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "netflix\n",
      "netflix\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBC\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "NetflixUK\n",
      "netflix\n",
      "BBCOne\n",
      "Disne\n",
      "Disne\n",
      "Disne\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "Disne\n",
      "Disne\n",
      "BBCOne\n",
      "DisneyP\n",
      "A\n",
      "DisneyP\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "DisneyP\n",
      "A\n",
      "Disn\n",
      "Disn\n",
      "Disne\n",
      "Disne\n",
      "BBCOne\n",
      "NetflixUK\n",
      "AppleTV\n",
      "BBC\n",
      "NetflixUK\n",
      "NetflixUK\n",
      "Dis\n",
      "Dis\n",
      "Dis\n",
      "Dis\n",
      "primevideouk\n",
      "primevideouk\n",
      "NetflixUK\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "NetflixUK\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "Dis\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "NetflixUK\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "Di\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "primevideouk\n",
      "Disne\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "BBC\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "BBC\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "BBC\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "BBC\n",
      "netflix\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "BBC\n",
      "primevideouk\n",
      "Dis\n",
      "Dis\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "netflix\n",
      "Di\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "Di\n",
      "Dis\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "Dis\n",
      "Dis\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "D\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "netflix\n",
      "netflix\n",
      "BBC\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "AppleTV\n",
      "netflix\n",
      "NETFLIXUK\n",
      "NETFLIXUK\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "netflix\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "Netflix\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "AppleTV\n",
      "2\n",
      "2\n",
      "2\n",
      "primevideouk\n",
      "App\n",
      "App\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "primevideouk\n",
      "App\n",
      "primevideouk\n",
      "App\n",
      "BBCOne\n",
      "AppleTV\n",
      "App\n",
      "BBC\n",
      "BBC\n",
      "AppleTV\n",
      "Netflix\n",
      "Netflix\n",
      "Netflix\n",
      "Netflix\n",
      "Netflix\n",
      "Netflix\n",
      "primevideouk\n",
      "BBC\n",
      "BBCOne\n",
      "DisneyP\n",
      "Di\n",
      "Di\n",
      "Dis\n",
      "Disn\n",
      "DisneyP\n",
      "Dis\n",
      "D\n",
      "Disn\n",
      "Disn\n",
      "Dis\n",
      "Disn\n",
      "Disn\n",
      "D\n",
      "Dis\n",
      "Dis\n",
      "D\n",
      "Disn\n",
      "Dis\n",
      "D\n",
      "DisneyP\n",
      "Dis\n",
      "Dis\n",
      "Di\n",
      "D\n",
      "D\n",
      "Disn\n",
      "DisneyP\n",
      "D\n",
      "Disn\n",
      "Disn\n",
      "D\n",
      "Disn\n",
      "D\n",
      "Disn\n",
      "Disn\n",
      "Disn\n",
      "DisneyP\n",
      "Disn\n",
      "Disn\n",
      "D\n",
      "Disn\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "netflix\n",
      "Disn\n",
      "D\n",
      "Disn\n",
      "D\n",
      "NetflixUK\n",
      "Disn\n",
      "Disn\n",
      "Disn\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "Disn\n",
      "D\n",
      "Disn\n",
      "Disn\n",
      "Disn\n",
      "D\n",
      "D\n",
      "D\n",
      "Disn\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "Disn\n",
      "D\n",
      "D\n",
      "D\n",
      "Disn\n",
      "D\n",
      "D\n",
      "D\n",
      "Disn\n",
      "Disn\n",
      "Disn\n",
      "D\n",
      "Disn\n",
      "Disn\n",
      "Disn\n",
      "Disn\n",
      "Disn\n",
      "Disn\n",
      "D\n",
      "D\n",
      "Disn\n",
      "D\n",
      "Disn\n",
      "Disn\n",
      "D\n",
      "Disn\n",
      "Disn\n",
      "Disn\n",
      "Disn\n",
      "Disn\n",
      "D\n",
      "D\n",
      "netflix\n",
      "BBCOne\n",
      "HBO\n",
      "BBCOne\n",
      "HBO\n",
      "BBCOne\n",
      "HBO\n",
      "HBO\n",
      "HBO\n",
      "HBO\n",
      "HBO\n",
      "BBCOne\n",
      "HBO\n",
      "HBO\n",
      "netflix\n",
      "BBCOne\n",
      "HBO\n",
      "HBO\n",
      "HBO\n",
      "HBO\n",
      "HBO\n",
      "HBO\n",
      "HBO\n",
      "BBCOne\n",
      "NetflixUK\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "BBCOne\n",
      "Dis\n",
      "Dis\n",
      "Dis\n",
      "Dis\n",
      "Dis\n",
      "Empty DataFrame\n",
      "Columns: [tweet_id, from_, to_]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [tweet_id, from_, to_]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "na_interac_df =get_interaction(na_df)\n",
    "filter_out = ['2','A','App','AppleSupport','AppleTV','AppleTVI','AppleTVPlus','AppleTVUK','BB','BBC','BBCO','BBC','BBCOn', 'BBCOne', 'BBCPlayer','BBCSounds', 'BBCR1',\n",
    "                  'BBCSounds','BBCiPlayer','BBCone','D','Di','Dis','Disn', 'Disne', 'Dinsey',' DisneyChannel','DisneyHyperion','DisneyIT', 'DisneyP', 'DisneyChannel',\n",
    "                  'DisneyHyperion','DisneyPlusUK', 'DisneyPlus', 'HBO', 'HBO_UK','NETFLIX', 'netflix', 'NETFLIXUK', 'Netflix', 'NetflixUK','ParamountPlus', 'ParamaountUK', 'ParamountPlusUK'\n",
    "                  'Prime', 'PrimeUK', 'PrimeVideo', 'primevideouk']\n",
    "na_interac_df = na_interac_df[~na_interac_df['from_'].isin(filter_out)]\n",
    "na_interac_df = na_interac_df[~na_interac_df['to_'].isin(filter_out)]                            \n",
    "print(na_interac_df[na_interac_df['from_'].isin(filter_out)])\n",
    "print(na_interac_df[na_interac_df['to_'].isin(filter_out)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a unique user dataframe\n",
    "list_of_user = na_interac_df['from_'].append(na_interac_df['to_'], ignore_index=True)\n",
    "list_of_user = list(set(list_of_user))\n",
    "user_df = pd.DataFrame(list_of_user, columns=['username'])\n",
    "user_df['user'] = user_df['username'].apply(anonymize)\n",
    "user_df=user_df.sort_values('username').reset_index()\n",
    "user_df.to_csv('output/username.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anonymise the users from the different dataframes\n",
    "na_interac_df['from_'] = na_interac_df['from_'].map(user_df.set_index('username')['user'])\n",
    "na_interac_df['to_'] = na_interac_df['to_'].map(user_df.set_index('username')['user'])\n",
    "working_df['user'] = working_df['user'].map(user_df.set_index('username')['user'])\n",
    "na_interac_df.to_csv('output/userinteraction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = working_df[['tweet_id', 'created_at', 'user', 'full_text', 'favorite_count', 'retweet_count', 'retweet', 'week']]\n",
    "working_df.to_csv('output/tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(hashtags_df['tweet_id'])==set(working_df['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove existing database if available\n",
    "if os.path.exists('output/lnctweets.db'):\n",
    "    os.remove('output/lnctweets.db')\n",
    "# Creating a database file for the all the output csv file\n",
    "# Establish a connection to the SQLite Database\n",
    "conn = sqlite3.connect('output/lnctweets.db')\n",
    "# Create a cursor object to execute SQL statements:\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(table_name, columns):\n",
    "    create_table_query = f\"CREATE TABLE IF NOT EXISTS `{table_name}` ({', '.join(columns)})\"\n",
    "    cursor.execute(create_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to insert data into the table from a CSV file:\n",
    "def insert_data(table_name, csv_file):\n",
    "    with open(csv_file, 'r') as file:\n",
    "        csv_data = csv.reader(file)\n",
    "        next(csv_data)  # Skip the header row if necessary\n",
    "        num_columns = len(next(csv_data))\n",
    "        insert_query = f\"INSERT INTO {table_name} VALUES ({', '.join(['?'] * num_columns)})\"\n",
    "        cursor.executemany(insert_query, csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the CSV file paths and table names for each file:\n",
    "csv_files = ['output/hashtags.csv',  'output/tweets.csv', 'output/userinteraction.csv']\n",
    "table_names = ['hashtags', 'tweets', 'userinteraction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables and insert data for each CSV file:\n",
    "for i, csv_file in enumerate(csv_files):\n",
    "    table_name = table_names[i]\n",
    "    with open(csv_file, 'r') as file:\n",
    "        csv_data = csv.reader(file)\n",
    "        columns = next(csv_data)\n",
    "        data_type = ' TEXT'\n",
    "        columns = [x + data_type for x in columns]\n",
    "        #print(columns)\n",
    "        create_table(table_name, columns)\n",
    "        insert_data(table_name, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        tweet_id     from_       to_\n",
      "0       75c047d4  c25b9a3d  5cb9cb18\n",
      "1       aab6f161  385e7052  7af41a48\n",
      "2       2e91d9dc  cb33bb2d  f4b0e500\n",
      "3       c8f59c0c  3cfa784a  429542c4\n",
      "4       f7e7b3d6  e9a05361  e1362151\n",
      "...          ...       ...       ...\n",
      "157156  a6376cfa  8caa00a5  ba4f5917\n",
      "157157  a6376cfa  8caa00a5  73cbea66\n",
      "157158  8a640409  dc284ebb  01dac1ce\n",
      "157159  1d6acb9b  62f322a1  01dac1ce\n",
      "157160  2a0684c6  06b030f5  3b25e8a3\n",
      "\n",
      "[157161 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# open the tweets table in the .db file\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM userinteraction\n",
    "    \"\"\"\n",
    "conn = sqlite3.connect('output/lnctweets.db')\n",
    "print(pd.read_sql_query(query,conn))\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimal_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
